{
  "questions": [
    {
      "id": "451",
      "question": "A company is migrating its a pplications a nd databases to the A WS Cloud. The company will use A mazon Elastic Container Service (A mazon ECS), A WS Direct Connect, a nd A mazon RDS. Which a ctivities will be managed by the company's operational team? (Choose three.)",
      "options": {
        "A": "Management of the A mazon RDS infrastructure layer, operating system, a nd platforms",
        "B": "Creation of a n A mazon RDS DB instance a nd conFiguring the scheduled maintenance window",
        "C": "ConFiguration of a dditional software components on A mazon ECS for monitoring, patch management, log management, a nd host intrusion detection",
        "D": "Installation of patches for a ll minor a nd major database versions for A mazon RDS",
        "E": "Ensure the physical security of the A mazon RDS infrastructure in the data center F. Encryption of the data that moves in transit through Direct Connect"
      },
      "correct_answer": "C",
      "explanation": "The company's operational team is responsible for configuring a dditional software components on A mazon ECS, such a s monitoring tools, patch management tools, log management systems, a nd host intrusion detection systems. These components a re often specific to the company's requirements a nd policies.\nB. Creation of a n A mazon RDS DB instance a nd configuring the scheduled maintenance window:\nThe operational team is responsible for creating A mazon RDS DB instances, configuring parameters, a nd setting up maintenance windows based on the company's operational needs. This includes decisions a bout the size a nd type of the RDS instance, storage configuration, a nd other relevant settings.\nF. Encryption of the data that moves in transit through Direct Connect:\nWhile A WS manages the physical infrastructure of Direct Connect, the company's operational team is responsible for configuring encryption for the data in transit over Direct Connect. This includes implementing encryption protocols a nd ensuring the security of data while it travels between the on-premises data center a nd A WS."
    },
    {
      "id": "452",
      "question": "A company runs a Java-based job on a n A mazon EC2 instance. The job runs every hour a nd takes 10 seconds to run. The job runs on a scheduled interval a nd consumes 1 GB of memory. The CPU utilization of the instance is low except for short surges during which the job uses the maximum CPU a vailable. The company wants to optimize the costs to run the job. Which solution will meet these requirements?",
      "options": {
        "A": "Use A WS A pp2Container (A2C) to containerize the job. Run the job a s a n A mazon Elastic Container Service (A mazon ECS) task on A WS Fargate with 0.5 virtual CPU (vCPU) a nd 1 GB of memory.",
        "B": "Copy the code into a n A WS Lambda function that has 1 GB of memory. Create a n A mazon EventBridge scheduled rule to run the code each hour.",
        "C": "Use A WS A pp2Container (A2C) to containerize the job. Install the container in the existing A mazon Machine Image (A MI). Ensure that the schedule stops the container when the task Finishes.",
        "D": "Configure the existing schedule to stop the EC2 instance a t the completion of the job a nd restart the EC2 instance when the next job starts."
      },
      "correct_answer": "B",
      "explanation": "A WS Lambda is a serverless compute service that a llows you to run code without provisioning or managing servers. It a utomatically scales based on the number of requests, making it cost-effective for sporadic workloads.\nScheduled Rule with A mazon EventBridge:\nA mazon EventBridge a llows you to schedule events a t specified intervals. By creating a scheduled rule, you can trigger the Lambda function to run the Java-based job every hour."
    },
    {
      "id": "453",
      "question": "A company wants to implement a backup strategy for A mazon EC2 data a nd multiple A mazon S3 buckets. Because of regulatory requirements, the company must retain backup Files for a specific time period. The company must not a lter the Files for the duration of the retention period. Which solution will meet these requirements?",
      "options": {
        "A": "Use A WS Backup to create a backup vault that has a vault lock in governance mode. Create the required backup plan.",
        "B": "Use A mazon Data Lifecycle Manager to create the required a utomated snapshot policy.",
        "C": "Use A mazon S3 File Gateway to create the backup. Configure the a ppropriate S3 Lifecycle management.",
        "D": "Use A WS Backup to create a backup vault that has a vault lock in compliance mode. Create the required backup plan."
      },
      "correct_answer": "D",
      "explanation": "A WS Backup provides a centralized solution for managing backups a cross various A WS services, including A mazon EC2. By creating a backup vault with a vault lock in compliance mode, the company ensures that the backup files a re retained a nd cannot be a ltered for the duration of the retention period. Compliance mode is designed to meet regulatory requirements for data retention."
    },
    {
      "id": "454",
      "question": "A company has resources a cross multiple A WS Regions a nd a ccounts. A newly hired solutions a rchitect discovers a previous employee did not provide details a bout the resources inventory. The solutions a rchitect needs to build a nd map the relationship details of the various workloads a cross a ll a ccounts. Which solution will meet these requirements in the MOST operationally eficient way?",
      "options": {
        "A": "Use A WS Systems Manager Inventory to generate a map view from the detailed view report.",
        "B": "Use A WS Step Functions to collect workload details. Build a rchitecture diagrams of the workloads manually.",
        "C": "Use Workload Discovery on A WS to generate a rchitecture diagrams of the workloads.",
        "D": "Use A WS X-Ray to view the workload details. Build a rchitecture diagrams with relationships."
      },
      "correct_answer": "C",
      "explanation": "A WS has a service called A WS Well-A rchitected Tool, which includes Workload Discovery. Workload Discovery a utomatically discovers a nd visualizes the a rchitecture of your workloads. It provides a rchitecture diagrams, best practice recommendations, a nd insights into your workloads."
    },
    {
      "id": "455",
      "question": "A company uses A WS Organizations. The company wants to operate some of its A WS a ccounts with different budgets. The company wants to receive a lerts a nd a utomatically prevent provisioning of a dditional resources on A WS a ccounts when the a llocated budget threshold is met during a specific period. Which combination of solutions will meet these requirements? (Choose three.)",
      "options": {
        "A": "Use A WS Budgets to create a budget. Set the budget a mount under the Cost a nd Usage Reports section of the required A WS a ccounts.",
        "B": "Use A WS Budgets to create a budget. Set the budget a mount under the Billing dashboards of the required A WS a ccounts.",
        "C": "Create a n IAM user for A WS Budgets to run budget a ctions with the required permissions.",
        "D": "Create a n IAM role for A WS Budgets to run budget a ctions with the required permissions.",
        "E": "A dd a n a lert to notify the company when each a ccount meets its budget threshold. A dd a budget a ction that selects the IAM identity created with the a ppropriate conFig rule to prevent provisioning of a dditional resources. F. A dd a n a lert to notify the company when each a ccount meets its budget threshold. A dd a budget a ction that selects the IAM identity created with the a ppropriate service control policy (SCP) to prevent provisioning of a dditional resources."
      },
      "correct_answer": "B",
      "explanation": "D. Create a n IAM role for A WS Budgets to run budget a ctions with the required permissions.\nF. A dd a n a lert to notify the company when each a ccount meets its budget threshold. A dd a budget a ction that selects the IAM identity created with the a ppropriate service control policy (SCP) to prevent provisioning of a dditional resources."
    },
    {
      "id": "456",
      "question": "A company runs a pplications on A mazon EC2 instances in one A WS Region. The company wants to back up the EC2 instances to a second Region. The company a lso wants to provision EC2 resources in the second Region a nd manage the EC2 instances centrally from one A WS a ccount. Which solution will meet these requirements MOST cost-effectively?",
      "options": {
        "A": "Create a disaster recovery (DR) plan that has a similar number of EC2 instances in the second Region. Configure data replication.",
        "B": "Create point-in-time A mazon Elastic Block Store (A mazon EBS) snapshots of the EC2 instances. Copy the snapshots to the second Region periodically.",
        "C": "Create a backup plan by using A WS Backup. Configure cross-Region backup to the second Region for the EC2 instances.",
        "D": "Deploy a similar number of EC2 instances in the second Region. Use A WS DataSync to transfer the data from the source Region to the second Region."
      },
      "correct_answer": "C",
      "explanation": "A WS Backup is a centralized backup service that a llows you to create backup plans for various A WS resources, including EC2 instances. With A WS Backup, you can configure cross-Region backups, meaning you can replicate backups from one A WS Region to a nother. This provides a cost-effective a nd centralized solution for backup."
    },
    {
      "id": "457",
      "question": "A company that uses A WS is building a n a pplication to transfer data to a product manufacturer. The company has its own identity provider (IdP). The company wants the IdP to a uthenticate a pplication users while the users use the a pplication to transfer data. The company must use A pplicability Statement 2 (A S2) protocol. Which solution will meet these requirements?",
      "options": {
        "A": "Use A WS DataSync to transfer the data. Create a n A WS Lambda function for IdP a uthentication.",
        "B": "Use A mazon A ppFlow Flows to transfer the data. Create a n A mazon Elastic Container Service (A mazon ECS) task for IdP a uthentication.",
        "C": "Use A WS Transfer Family to transfer the data. Create a n A WS Lambda function for IdP a uthentication.",
        "D": "Use A WS Storage Gateway to transfer the data. Create a n A mazon Cognito identity pool for IdP a uthentication."
      },
      "correct_answer": "C",
      "explanation": "A WS Transfer Family (Option C): A WS Transfer Family is a fully managed service that a llows you to transfer files over the internet using a range of protocols, including A S2. You can integrate A WS Transfer Family with your IdP for user a uthentication. By using a Lambda function, you can customize the a uthentication process a nd integrate it with your own IdP."
    },
    {
      "id": "458",
      "question": "A solutions a rchitect is designing a RESTAPI in A mazon A PI Gateway for a cash payback service. The a pplication requires 1 GB of memory a nd 2 GB of storage for its computation resources. The a pplication will require that the data is in a relational format. Which a dditional combination ofAWS services will meet these requirements with the LEAST a dministrative effort? (Choose two.)",
      "options": {
        "A": "A mazon EC2",
        "B": "A WS Lambda",
        "C": "A mazon RDS",
        "D": "A mazon DynamoDB",
        "E": "A mazon Elastic Kubernetes Services (A mazon EKS)"
      },
      "correct_answer": "BC",
      "explanation": "C. A mazon RDS\nA WS Lambda is a serverless compute service that a utomatically scales based on the number of requests a nd executes your code without requiring you to provision or manage servers. It's event-driven, a nd you pay only for the compute time consumed. For a REST A PI, Lambda can be a low-a dministration solution compared to managing infrastructure directly.\nA mazon RDS (Relational Database Service) is a fully managed relational database service that simplifies database a dministration tasks. It provides options for popular database engines like MySQL, PostgreSQL, Oracle, a nd Microsoft SQL Server. You can easily provision, scale, a nd manage a relational database without dealing with the underlying infrastructure."
    },
    {
      "id": "459",
      "question": "A company uses A WS Organizations to run workloads within multiple A WS a ccounts. A tagging policy a dds department tags to A WS resources when the company creates tags. A n a ccounting team needs to determine spending on A mazon EC2 consumption. The a ccounting team must determine which departments a re responsible for the costs regardless ofAWS a ccount. The a ccounting team has a ccess to A WS Cost Explorer for a ll A WS a ccounts within the organization a nd needs to a ccess a ll reports from Cost Explorer. Which solution meets these requirements in the MOST operationally eficient way?",
      "options": {
        "A": "From the Organizations management a ccount billing console, a ctivate a user-deFined cost a llocation tag named department. Create one cost report in Cost Explorer grouping by tag name, a nd Filter by EC2.",
        "B": "From the Organizations management a ccount billing console, a ctivate a n A WS-deFined cost a llocation tag named department. Create one cost report in Cost Explorer grouping by tag name, a nd Filter by EC2.",
        "C": "From the Organizations member a ccount billing console, a ctivate a user-deFined cost a llocation tag named department. Create one cost report in Cost Explorer grouping by the tag name, a nd Filter by EC2.",
        "D": "From the Organizations member a ccount billing console, a ctivate a n A WS-deFined cost a llocation tag named department. Create one cost report in Cost Explorer grouping by tag name, a nd Filter by EC2."
      },
      "correct_answer": "A",
      "explanation": "While A WS provides A WS-defined tags, the use of a user-defined tag provides flexibility in terms of naming a nd tagging conventions. A ctivating the tag a t the Organizations management a ccount level ensures that the tag is a pplied to resources a cross a ll member a ccounts."
    },
    {
      "id": "460",
      "question": "A company wants to securely exchange data between its software a s a service (SaaS) a pplication Salesforce a ccount a nd A mazon S3. The company must encrypt the data a t rest by using A WS Key Management Service (A WS KMS) customer managed keys (CMKs). The company must a lso encrypt the data in transit. The company has enabled A PI a ccess for the Salesforce a ccount.",
      "options": {
        "A": "Create A WS Lambda functions to transfer the data securely from Salesforce to A mazon S3.",
        "B": "Create a n A WS Step Functions workflow. DeFine the task to transfer the data securely from Salesforce to A mazon S3.",
        "C": "Create A mazon A ppFlow Flows to transfer the data securely from Salesforce to A mazon S3.",
        "D": "Create a custom connector for Salesforce to transfer the data securely from Salesforce to A mazon S3."
      },
      "correct_answer": "C",
      "explanation": "A mazon A ppFlow is a fully managed integration service that a llows you to securely transfer data between A WS services a nd SaaS a pplications like Salesforce. It supports data encryption both in transit a nd a t rest. With A ppFlow, you can configure the integration flow, including source (Salesforce) a nd destination (A mazon S3), a nd set up encryption options. It simplifies the data transfer process a nd can handle the encryption requirements without the need for custom development."
    },
    {
      "id": "461",
      "question": "A company is developing a mobile gaming a pp in a single A WS Region. The a pp runs on multiple A mazon EC2 instances in a n A uto Scaling group. The company stores the a pp data in A mazon DynamoDB. The a pp communicates by using TCP traffic a nd UDP traffic between the users a nd the servers. The a pplication will be used globally. The company wants to ensure the lowest possible latency for a ll users. Which solution will meet these requirements?",
      "options": {
        "A": "Use A WS Global A ccelerator to create a n a ccelerator. Create a n A pplication Load Balancer (A LB) behind a n a ccelerator endpoint that uses Global A ccelerator integration a nd listening on the TCP a nd UDP ports. Update the A uto Scaling group to register instances on the A LB.",
        "B": "Use A WS Global A ccelerator to create a n a ccelerator. Create a Network Load Balancer (NLB) behind a n a ccelerator endpoint that uses Global A ccelerator integration a nd listening on the TCP a nd UDP ports. Update the A uto Scaling group to register instances on the NLB.",
        "C": "Create a n A mazon CloudFront content delivery network (CDN) endpoint. Create a Network Load Balancer (NLB) behind the endpoint a nd listening on the TCP a nd UDP ports. Update the A uto Scaling group to register instances on the NLB. Update CloudFront to use the NLB a s the origin.",
        "D": "Create a n A mazon CloudFront content delivery network (CDN) endpoint. Create a n A pplication Load Balancer (A LB) behind the endpoint a nd listening on the TCP a nd UDP ports. Update the A uto Scaling group to register instances on the A LB. Update CloudFront to use the A LB a s the origin."
      },
      "correct_answer": "B",
      "explanation": ""
    },
    {
      "id": "462",
      "question": "A company has a n a pplication that processes customer orders. The company hosts the a pplication on a n A mazon EC2 instance that saves the orders to a n A mazon A urora database. Occasionally when traffic is high the workload does not process orders fast enough. What should A solutions a rchitect do to write the orders reliably to the database a s quickly a s possible?",
      "options": {
        "A": "Increase the instance size of the EC2 instance when traffic is high. Write orders to A mazon Simple NotiFication Service (A mazon SNS). Subscribe the database endpoint to the SNS topic.",
        "B": "Write orders to a n A mazon Simple Queue Service (A mazon SQS) queue. Use EC2 instances in a n A uto Scaling group behind a n A pplication Load Balancer to read from the SQS queue a nd process orders into the database.",
        "C": "Write orders to A mazon Simple NotiFication Service (A mazon SNS). Subscribe the database endpoint to the SNS topic. Use EC2 instances in a n A uto Scaling group behind a n A pplication Load Balancer to read from the SNS topic.",
        "D": "Write orders to a n A mazon Simple Queue Service (A mazon SQS) queue when the EC2 instance reaches CPU threshold limits. Use scheduled scaling of EC2 instances in a n A uto Scaling group behind a n A pplication Load Balancer to read from the SQS queue a nd process orders into the database."
      },
      "correct_answer": "B",
      "explanation": "A mazon SQS, which is a fully managed message queuing service. Writing orders to a n SQS queue a llows for decoupling the EC2 instances processing the orders from the a pplication writing the orders. EC2 instances in a n A uto Scaling group can then read from the SQS queue, ensuring that the processing scales with demand.\nUsing a n A uto Scaling group ensures that you can dynamically a djust the number of EC2 instances based on the workload. This can help handle high traffic efficiently."
    },
    {
      "id": "463",
      "question": "A n IoT company is releasing a mattress that has sensors to collect data a bout a user\u2019s sleep. The sensors will send data to a n A mazon S3 bucket. The sensors collect a pproximately 2 MB of data every night for each mattress. The company must process a nd summarize the data for each mattress. The results need to be a vailable a s soon a s possible. Data processing will require 1 GB of memory a nd will Finish within 30 seconds. Which solution will meet these requirements MOST cost-effectively?",
      "options": {
        "A": "Use A WS Glue with a Scala job",
        "B": "Use A mazon EMR with a n A pache Spark script",
        "C": "Use A WS Lambda with a Python script",
        "D": "Use A WS Glue with a PySpark job"
      },
      "correct_answer": "C",
      "explanation": "A WS Lambda is a serverless compute service that a llows you to run code without provisioning or managing servers. It a utomatically scales with the number of requests, making it well-suited for event-driven workloads like processing data from IoT devices.\nPython is a lightweight a nd efficient language for data processing tasks.\nLambda a llows you to execute code in response to events, such a s data a rriving in the S3 bucket."
    },
    {
      "id": "464",
      "question": "A company hosts a n online shopping a pplication that stores a ll orders in a n A mazon RDS for PostgreSQL Single-A Z DB instance. Management wants to eliminate single points of failure a nd has a sked A solutions a rchitect to recommend a n a pproach to minimize database downtime without requiring a ny changes to the a pplication code. Which solution meets these requirements?",
      "options": {
        "A": "Convert the existing database instance to a Multi-A Z deployment by modifying the database instance a nd specifying the Multi-A Z option.",
        "B": "Create a new RDS Multi-A Z deployment. Take a snapshot of the current RDS instance a nd restore the new Multi-A Z deployment with the snapshot.",
        "C": "Create a read-only replica of the PostgreSQL database in a nother A vailability Zone. Use A mazon Route 53 weighted record sets to distribute requests a cross the databases.",
        "D": "Place the RDS for PostgreSQL database in a n A mazon EC2 A uto Scaling group with a minimum group size of two. Use A mazon Route 53 weighted record sets to distribute requests a cross instances."
      },
      "correct_answer": "A",
      "explanation": "By converting the existing RDS instance to a Multi-A Z deployment, you enable high a vailability with a utomatic failover. A mazon RDS will a utomatically replicate the database to a standby instance in a different A vailability Zone (A Z). In the event of a failure, A mazon RDS will a utomatically promote the standby to the primary, minimizing downtime."
    },
    {
      "id": "465",
      "question": "A company is developing a n a pplication to support customer demands. The company wants to deploy the a pplication on multiple A mazon EC2 Nitro-based instances within the same A vailability Zone. The company a lso wants to give the a pplication the a bility to write to multiple block storage volumes in multiple EC2 Nitro-based instances simultaneously to a chieve higher a pplication a vailability. Which solution will meet these requirements?",
      "options": {
        "A": "Use General Purpose SSD (gp3) EBS volumes with A mazon Elastic Block Store (A mazon EBS) Multi-A ttach",
        "B": "Use Throughput Optimized HDD (st1) EBS volumes with A mazon Elastic Block Store (A mazon EBS) Multi-A ttach",
        "C": "Use Provisioned IOPS SSD (io2) EBS volumes with A mazon Elastic Block Store (A mazon EBS) Multi-A ttach",
        "D": "Use General Purpose SSD (gp2) EBS volumes with A mazon Elastic Block Store (A mazon EBS) Multi-A ttach"
      },
      "correct_answer": "C",
      "explanation": "Provisioned IOPS SSD (io2) volumes do indeed support Multi-A ttach, a llowing you to a ttach a single volume to multiple Nitro-based instances in the same A vailability Zone. This can be suitable for scenarios where multiple instances need simultaneous a ccess to a shared volume with high performance."
    },
    {
      "id": "466",
      "question": "A company designed a stateless two-tier a pplication that uses A mazon EC2 in a single A vailability Zone a nd a n A mazon RDS Multi-A Z DB instance. New company management wants to ensure the a pplication is highly a vailable. What should A solutions a rchitect do to meet this requirement?",
      "options": {
        "A": "Configure the a pplication to use Multi-A Z EC2 A uto Scaling a nd create a n A pplication Load Balancer",
        "B": "Configure the a pplication to take snapshots of the EC2 instances a nd send them to a different A WS Region",
        "C": "Configure the a pplication to use A mazon Route 53 latency-based routing to feed requests to the a pplication",
        "D": "Configure A mazon Route 53 rules to handle incoming requests a nd create a Multi-A Z A pplication Load Balancer"
      },
      "correct_answer": "A",
      "explanation": ""
    },
    {
      "id": "467",
      "question": "A company uses A WS Organizations. A member a ccount has purchased a Compute Savings Plan. Because of changes in the workloads inside the member a ccount, the a ccount no longer receives the full benefit of the Compute Savings Plan commitment. The company uses less than 50% of its purchased compute power.",
      "options": {
        "A": "Turn on discount sharing from the Billing Preferences section of the a ccount console in the member a ccount that purchased the Compute Savings Plan.",
        "B": "Turn on discount sharing from the Billing Preferences section of the a ccount console in the company's Organizations management a ccount.",
        "C": "Migrate a dditional compute workloads from a nother A WS a ccount to the a ccount that has the Compute Savings Plan.",
        "D": "Sell the excess Savings Plan commitment in the Reserved Instance Marketplace."
      },
      "correct_answer": "B",
      "explanation": ""
    },
    {
      "id": "468",
      "question": "A company is developing a microservices a pplication that will provide a search catalog for customers. The company must use REST A PIs to present the frontend of the a pplication to users. The REST A PIs must a ccess the backend services that the company hosts in containers in private VPC subnets. Which solution will meet these requirements?",
      "options": {
        "A": "Design a WebSocket A PI by using A mazon A PI Gateway. Host the a pplication in A mazon Elastic Container Service (A mazon ECS) in a private subnet. Create a private VPC link for A PI Gateway to a ccess A mazon ECS.",
        "B": "Design a REST A PI by using A mazon A PI Gateway. Host the a pplication in A mazon Elastic Container Service (A mazon ECS) in a private subnet. Create a private VPC link for A PI Gateway to a ccess A mazon ECS.",
        "C": "Design a WebSocket A PI by using A mazon A PI Gateway. Host the a pplication in A mazon Elastic Container Service (A mazon ECS) in a private subnet. Create a security group for A PI Gateway to a ccess A mazon ECS.",
        "D": "Design a REST A PI by using A mazon A PI Gateway. Host the a pplication in A mazon Elastic Container Service (A mazon ECS) in a private subnet. Create a security group for A PI Gateway to a ccess A mazon ECS."
      },
      "correct_answer": "B",
      "explanation": ""
    },
    {
      "id": "469",
      "question": "A company stores raw collected data in a n A mazon S3 bucket. The data is used for several types of a nalytics on behalf of the company's customers. The type of a nalytics requested determines the a ccess pattern on the S3 objects. The company cannot predict or control the a ccess pattern. The company wants to reduce its S3 costs. Which solution will meet these requirements?",
      "options": {
        "A": "Use S3 replication to transition infrequently a ccessed objects to S3 Standard-Infrequent A ccess (S3 Standard-IA)",
        "B": "Use S3 Lifecycle rules to transition objects from S3 Standard to Standard-Infrequent A ccess (S3 Standard-IA)",
        "C": "Use S3 Lifecycle rules to transition objects from S3 Standard to S3 Intelligent-Tiering",
        "D": "Use S3 Inventory to identify a nd transition objects that have not been a ccessed from S3 Standard to S3 Intelligent-Tiering"
      },
      "correct_answer": "C",
      "explanation": "S3 Intelligent-Tiering is designed to optimize costs by a utomatically moving objects between two a ccess tiers: frequent a nd infrequent a ccess. It is well-suited for scenarios where a ccess patterns a re unpredictable.\nUsing S3 Lifecycle rules to transition objects to S3 Intelligent-Tiering a llows you to take a dvantage of a utomatic cost savings based on a ctual a ccess patterns without the need for manual a djustments."
    },
    {
      "id": "470",
      "question": "A company has a pplications hosted on A mazon EC2 instances with IPv6 a ddresses. The a pplications must initiate communications with other external a pplications using the internet. However the company\u2019s security policy states that a ny external service cannot initiate a connection to the EC2 instances. What should A solutions a rchitect recommend to resolve this issue?",
      "options": {
        "A": "Create a NAT gateway a nd make it the destination of the subnet's route table",
        "B": "Create a n internet gateway a nd make it the destination of the subnet's route table",
        "C": "Create a virtual private gateway a nd make it the destination of the subnet's route table",
        "D": "Create a n egress-only internet gateway a nd make it the destination of the subnet's route table"
      },
      "correct_answer": "D",
      "explanation": "A n egress-only internet gateway is used for IPv6 traffic leaving the VPC to reach the internet. It a llows outbound communication initiated by resources inside the VPC but prevents incoming traffic initiated from the internet.\nConfiguring the subnet's route table to use the egress-only internet gateway a s the destination ensures that IPv6 traffic initiated from EC2 instances can reach external services while blocking unsolicited incoming traffic."
    },
    {
      "id": "471",
      "question": "A company is creating a n a pplication that runs on containers in a VPC. The a pplication stores a nd a ccesses data in a n A mazon S3 bucket. During the development phase, the a pplication will store a nd a ccess 1 TB of data in A mazon S3 each day. The company wants to minimize costs a nd wants to prevent traffic from traversing the internet whenever possible. Which solution will meet these requirements?",
      "options": {
        "A": "Enable S3 Intelligent-Tiering for the S3 bucket",
        "B": "Enable S3 Transfer A cceleration for the S3 bucket",
        "C": "Create a gateway VPC endpoint for A mazon S3. A ssociate this endpoint with a ll route tables in the VPC",
        "D": "Create a n interface endpoint for A mazon S3 in the VPC. A ssociate this endpoint with a ll route tables in the VPC"
      },
      "correct_answer": "C",
      "explanation": "Gateway VPC Endpoint: A gateway VPC endpoint enables private connectivity between a VPC a nd A mazon S3. It a llows direct a ccess to A mazon S3 without the need for internet gateways, NAT devices, VPN connections, or A WS Direct Connect."
    },
    {
      "id": "472",
      "question": "A company has a mobile chat a pplication with a data store based in A mazon DynamoDB. Users would like new messages to be read with a s little latency a s possible. A solutions a rchitect needs to design a n optimal solution that requires minimal a pplication changes. Which method should the solutions a rchitect select?",
      "options": {
        "A": "Configure A mazon DynamoDB A ccelerator (DAX) for the new messages table. Update the code to use the DAX endpoint.",
        "B": "A dd DynamoDB read replicas to handle the increased read load. Update the a pplication to point to the read endpoint for the read replicas.",
        "C": "Double the number of read capacity units for the new messages table in DynamoDB. Continue to use the existing DynamoDB endpoint.",
        "D": "A dd a n A mazon ElastiCache for Redis cache to the a pplication stack. Update the a pplication to point to the Redis cache endpoint instead of DynamoDB."
      },
      "correct_answer": "A",
      "explanation": "A mazon DynamoDB A ccelerator (DAX) is a n in-memory caching service for DynamoDB that helps improve the read performance of DynamoDB tables.A company hosts a website on A mazon EC2 instances behind a n A pplication Load Balancer (A LB). The website serves static content. Website traffic is increasing, a nd the company is concerned a bout a potential increase in cost."
    },
    {
      "id": "473",
      "question": "A company hosts a website on A mazon EC2 instances behind a n A pplication Load Balancer (A LB). The website serves static content. Website traffic is increasing, a nd the company is concerned a bout a potential increase in cost.",
      "options": {
        "A": "Create a n A mazon CloudFront distribution to cache state Files a t edge locations",
        "B": "Create a n A mazon ElastiCache cluster. Connect the A LB to the ElastiCache cluster to serve cached Files",
        "C": "Create a n A WS WAF web A CL a nd a ssociate it with the A LB. A dd a rule to the web A CL to cache static Files",
        "D": "Create a second A LB in a n a lternative A WS Region. Route user traffic to the closest Region to minimize data transfer costs"
      },
      "correct_answer": "A",
      "explanation": "By creating a CloudFront distribution a nd configuring it to cache static files, you can offload the delivery of static content to the CDN, reducing the load on the A LB a nd potentially lowering data transfer costs.\nCloudFront helps improve website performance a nd can be cost-effective due to its caching mechanism."
    },
    {
      "id": "474",
      "question": "A company has multiple VPCs a cross A WS Regions to support a nd run workloads that a re isolated from workloads in other Regions. Because of a recent a pplication launch requirement, the company\u2019s VPCs must communicate with a ll other VPCs a cross a ll Regions. Which solution will meet these requirements with the LEAST a mount of a dministrative effort?",
      "options": {
        "A": "Use VPC peering to manage VPC communication in a single Region. Use VPC peering a cross Regions to manage VPC communications.",
        "B": "Use A WS Direct Connect gateways a cross a ll Regions to connect VPCs a cross regions a nd manage VPC communications.",
        "C": "Use A WS Transit Gateway to manage VPC communication in a single Region a nd Transit Gateway peering a cross Regions to manage VPC communications.",
        "D": "Use A WS PrivateLink a cross a ll Regions to connect VPCs a cross Regions a nd manage VPC communications"
      },
      "correct_answer": "C",
      "explanation": "A WS Transit Gateway is designed for simplifying the connectivity between multiple VPCs a nd on-premises networks. It a llows for hub-a nd-spoke connectivity patterns, making it easier to manage communication a cross multiple VPCs.\nBy using A WS Transit Gateway in a single Region to connect VPCs a nd enabling Transit Gateway peering a cross Regions, you can efficiently manage communication between VPCs in different Regions with centralized control a nd minimal a dministrative effort."
    },
    {
      "id": "475",
      "question": "A company is designing a containerized a pplication that will use A mazon Elastic Container Service (A mazon ECS). The a pplication needs to a ccess a shared File system that is highly durable a nd can recover data to a nother A WS Region with a recovery point objective (RPO) of 8 hours. The File system needs to provide a mount target meach A vailability Zone within a Region. A solutions a rchitect wants to use A WS Backup to manage the replication to a nother Region. Which solution will meet these requirements?",
      "options": {
        "A": "A mazon FSx for Windows File Server with a Multi-A Z deployment",
        "B": "A mazon FSx for NetApp ONTAP with a Multi-A Z deployment",
        "C": "A mazon Elastic File System (A mazon EFS) with the Standard storage class",
        "D": "A mazon FSx for OpenZFS"
      },
      "correct_answer": "C",
      "explanation": ""
    },
    {
      "id": "476",
      "question": "A company is expecting rapid growth in the near future. A solutions a rchitect needs to configure existing users a nd grant permissions to new users on A WS. The solutions a rchitect has decided to create IAM groups. The solutions a rchitect will a dd the new users to IAM groups based on department. Which a dditional a ction is the MOST secure way to grant permissions to the new users?",
      "options": {
        "A": "A pply service control policies (SCPs) to manage a ccess permissions",
        "B": "Create IAM roles that have least privilege permission. A ttach the roles to the IAM groups",
        "C": "Create a n IAM policy that grants least privilege permission. A ttach the policy to the IAM groups",
        "D": "Create IAM roles. A ssociate the roles with a permissions boundary that deFines the maximum permissions"
      },
      "correct_answer": "C",
      "explanation": "Creating a n IAM policy that grants the least privilege required for the users' tasks is a security best practice. By a ttaching this policy to IAM groups, you ensure that new users a dded to these groups inherit the specific permissions defined in the policy."
    },
    {
      "id": "477",
      "question": "A group requires permissions to list a n A mazon S3 bucket a nd delete objects from that bucket. A n a dministrator has created the following IAM policy to provide a ccess to the bucket a nd a pplied that policy to the group. The group is not a ble to delete objects in the bucket. The company follows least-privilege a ccess rules. Which statement should A solutions a rchitect a dd to the policy to correct bucket a ccess?",
      "options": {
        "A": "",
        "B": "",
        "C": "",
        "D": ""
      },
      "correct_answer": "A",
      "explanation": ""
    },
    {
      "id": "478",
      "question": "A law Firm needs to share information with the public. The information includes hundreds of Files that must be publicly readable. Modifications or deletions of the Files by a nyone before a designated future date a re prohibited. Which solution will meet these requirements in the MOST secure way?",
      "options": {
        "A": "Upload a ll Files to a n A mazon S3 bucket that is conFigured for static website hosting. Grant read-only IAM permissions to a ny A WS principals that a ccess the S3 bucket until the designated date.",
        "B": "Create a new A mazon S3 bucket with S3 Versioning enabled. Use S3 Object Lock with a retention period in a ccordance with the designated date. Configure the S3 bucket for static website hosting. Set a n S3 bucket policy to a llow read-only a ccess to the objects.",
        "C": "Create a new A mazon S3 bucket with S3 Versioning enabled. Configure a n event trigger to run a n A WS Lambda function in case of object modiFication or deletion. Configure the Lambda function to replace the objects with the original versions from a private S3 bucket.",
        "D": "Upload a ll Files to a n A mazon S3 bucket that is conFigured for static website hosting. Select the folder that contains the Files. Use S3 Object Lock with a retention period in a ccordance with the designated date. Grant read-only IAM permissions to a ny A WS principals that a ccess the S3 bucket."
      },
      "correct_answer": "B",
      "explanation": "S3 Versioning helps maintain multiple versions of a n object over time. With S3 Object Lock, you can enforce retention periods during which the objects cannot be modified or deleted. This a ligns with the requirement to prohibit modifications or deletions before a designated future date."
    },
    {
      "id": "479",
      "question": "A company is making a prototype of the infrastructure for its new website by manually provisioning the necessary infrastructure. This infrastructure includes a n A uto Scaling group, a n A pplication Load Balancer a nd a n A mazon RDS database. A fter the configuration has been thoroughly validated, the company wants the capability to immediately deploy the infrastructure for development a nd production use in two A vailability Zones in a n a utomated fashion. What should A solutions a rchitect recommend to meet these requirements?",
      "options": {
        "A": "Use A WS Systems Manager to replicate a nd provision the prototype infrastructure in two A vailability Zones",
        "B": "DeFine the infrastructure a s a template by using the prototype infrastructure a s a guide. Deploy the infrastructure with A WS CloudFormation.",
        "C": "Use A WS ConFig to record the inventory of resources that a re used in the prototype infrastructure. Use A WS ConFig to deploy the prototype infrastructure into two A vailability Zones.",
        "D": "Use A WS Elastic Beanstalk a nd conFigure it to use a n a utomated reference to the prototype infrastructure to a utomatically deploy new environments in two A vailability Zones."
      },
      "correct_answer": "B",
      "explanation": "A WS CloudFormation is a service specifically designed for defining a nd deploying A WS infrastructure a s code using templates. In this case, you can create a CloudFormation template based on the validated prototype infrastructure, a nd then use CloudFormation to deploy a nd manage the infrastructure in a n a utomated a nd repeatable way."
    },
    {
      "id": "480",
      "question": "A business a pplication is hosted on A mazon EC2 a nd uses A mazon S3 for encrypted object storage. The chief information security oficer has directed that no a pplication traffic between the two services should traverse the public internet. Which capability should the solutions a rchitect use to meet the compliance requirements?",
      "options": {
        "A": "A WS Key Management Service (A WS KMS)",
        "B": "VPC endpoint",
        "C": "Private subnet",
        "D": "Virtual private gateway"
      },
      "correct_answer": "B",
      "explanation": "A WS provides VPC endpoints that a llow you to privately connect your VPC to supported A WS services, including A mazon S3, without needing to use public IP a ddresses or traverse the public internet.\nWith a n S3 VPC endpoint, the traffic between your A mazon EC2 instances a nd A mazon S3 remains within the A WS network, providing a secure a nd private connection."
    },
    {
      "id": "481",
      "question": "A company hosts a three-tier web a pplication in the A WS Cloud. A Multi-A Z A mazon RDS for MySQL server forms the database layer A mazon Elasticache forms the cache layer. The company wants a caching strategy that a dds or updates data in the cache when a customer a dds a n item to the database. The data in the cache must a lways match the data in the database. Which solution will meet these requirements?",
      "options": {
        "A": "Implement the lazy loading caching strategy",
        "B": "Implement the write-through caching strategy",
        "C": "Implement the a dding TTL caching strategy",
        "D": "Implement the A WS A ppConFig caching strategy"
      },
      "correct_answer": "B",
      "explanation": "In a write-through caching strategy, data is a lways written or updated in the cache when it is modified in the database. This ensures that the cache is consistently updated with the latest data from the database.\nWhen a customer a dds a n item to the database, the write-through caching strategy ensures that the item is a lso a dded or updated in the cache."
    },
    {
      "id": "482",
      "question": "A company wants to migrate 100 GB of historical data from a n on-premises location to a n A mazon S3 bucket. The company has a 100 megabits per second (Mbps) internet connection on premises. The company needs to encrypt the data in transit to the S3 bucket. The company will store new data directly in A mazon S3. Which solution will meet these requirements with the LEAST operational overhead?",
      "options": {
        "A": "Use the s3 sync command in the A WS CLI to move the data directly to a n S3 bucket",
        "B": "Use A WS DataSync to migrate the data from the on-premises location to a n S3 bucket",
        "C": "Use A WS Snowball to move the data to a n S3 bucket",
        "D": "Set up a n IPsec VPN from the on-premises location to A WS. Use the s3 cp command in the A WS CLI to move the data directly to a n S3 bucket"
      },
      "correct_answer": "B",
      "explanation": "A WS DataSync is a service designed for efficiently transferring large a mounts of data between on-premises storage systems a nd A mazon S3.\nIt supports encryption of data in transit, ensuring the security of the data during the migration process.\nA WS DataSync is specifically built for data transfer scenarios a nd minimizes operational overhead, providing a n efficient a nd straightforward solution."
    },
    {
      "id": "483",
      "question": "A company containerized a Windows job that runs on .NET 6 Framework under a Windows container. The company wants to run this job in the A WS Cloud. The job runs every 10 minutes. The job\u2019s runtime varies between 1 minute a nd 3 minutes. Which solution will meet these requirements MOST cost-effectively?",
      "options": {
        "A": "Create a n A WS Lambda function based on the container image of the job. Configure A mazon EventBridge to invoke the function every 10 minutes.",
        "B": "Use A WS Batch to create a job that uses A WS Fargate resources. Configure the job scheduling to run every 10 minutes.",
        "C": "Use A mazon Elastic Container Service (A mazon ECS) on A WS Fargate to run the job. Create a scheduled task based on the container image of the job to run every 10 minutes.",
        "D": "Use A mazon Elastic Container Service (A mazon ECS) on A WS Fargate to run the job. Create a standalone task based on the container image of the job. Use Windows task scheduler to run the job every 10 minutes."
      },
      "correct_answer": "C",
      "explanation": "A mazon ECS is a fully managed container orchestration service, a nd A WS Fargate a llows you to run containers without managing the underlying infrastructure.\nECS on Fargate is a serverless option, which means you only pay for the vCPU a nd memory that you use, a nd it scales a utomatically to meet the needs of the job."
    },
    {
      "id": "484",
      "question": "A company wants to move from many standalone A WS a ccounts to a consolidated, multi-a ccount a rchitecture. The company plans to create many new A WS a ccounts for different business units. The company needs to a uthenticate a ccess to these A WS a ccounts by using a centralized corporate directory service. Which combination of a ctions should A solutions a rchitect recommend to meet these requirements? (Choose two.)",
      "options": {
        "A": "Create a new organization in A WS Organizations with a ll features turned on. Create the new A WS a ccounts in the organization.",
        "B": "Set up a n A mazon Cognito identity pool. Configure A WS IAM Identity Center (A WS Single Sign-On) to a ccept A mazon Cognito a uthentication.",
        "C": "Configure a service control policy (SCP) to manage the A WS a ccounts. A dd A WS IAM Identity Center (A WS Single Sign-On) to A WS Directory Service.",
        "D": "Create a new organization in A WS Organizations. Configure the organization's a uthentication mechanism to use A WS Directory Service directly.",
        "E": "Set up A WS IAM Identity Center (A WS Single Sign-On) in the organization. Configure IAM Identity Center, a nd integrate it with the company's corporate directory service."
      },
      "correct_answer": "AE",
      "explanation": "E. Set up A WS IAM Identity Center (A WS Single Sign-On) in the organization. Configure IAM Identity Center, a nd integrate it with the company's corporate directory service.\nCreate a new organization in A WS Organizations with a ll features turned on. Create the new A WS a ccounts in the organization. This is a foundational step for managing multiple A WS a ccounts in a consolidated manner.\nOption E: Set up A WS IAM Identity Center (A WS Single Sign-On) in the organization. Configure IAM Identity Center, a nd integrate it with the company's corporate directory service. A WS Single Sign-On (SSO) is designed to simplify a nd centralize a uthentication a cross multiple A WS a ccounts."
    },
    {
      "id": "485",
      "question": "A company is looking for a solution that can store video a rchives in A WS from old news footage. The company needs to minimize costs a nd will rarely need to restore these Files. When the Files a re needed, they must be a vailable in a maximum of Five minutes. What is the MOST cost-effective solution?",
      "options": {
        "A": "Store the video a rchives in A mazon S3 Glacier a nd use Expedited retrievals.",
        "B": "Store the video a rchives in A mazon S3 Glacier a nd use Standard retrievals.",
        "C": "Store the video a rchives in A mazon S3 Standard-Infrequent A ccess (S3 Standard-IA).",
        "D": "Store the video a rchives in A mazon S3 One Zone-Infrequent A ccess (S3 One Zone-IA)."
      },
      "correct_answer": "A",
      "explanation": ""
    },
    {
      "id": "486",
      "question": "A company is building a three-tier a pplication on A WS. The presentation tier will serve a static website The logic tier is a containerized a pplication. This a pplication will store data in a relational database. The company wants to simplify deployment a nd to reduce operational costs. Which solution will meet these requirements?",
      "options": {
        "A": "Use A mazon S3 to host static content. Use A mazon Elastic Container Service (A mazon ECS) with A WS Fargate for compute power. Use a managed A mazon RDS cluster for the database.",
        "B": "Use A mazon CloudFront to host static content. Use A mazon Elastic Container Service (A mazon ECS) with A mazon EC2 for compute power. Use a managed A mazon RDS cluster for the database.",
        "C": "Use A mazon S3 to host static content. Use A mazon Elastic Kubernetes Service (A mazon EKS) with A WS Fargate for compute power. Use a managed A mazon RDS cluster for the database.",
        "D": "Use A mazon EC2 Reserved Instances to host static content. Use A mazon Elastic Kubernetes Service (A mazon EKS) with A mazon EC2 for compute power. Use a managed A mazon RDS cluster for the database."
      },
      "correct_answer": "A",
      "explanation": "A mazon S3 is a highly scalable a nd cost-effective storage service that can be used to host static content like a static website. It simplifies the storage a nd delivery of static a ssets.\nA WS Fargate is a serverless compute engine for containers. It a llows you to run containers without managing the underlying infrastructure. This simplifies deployment a nd reduces operational overhead."
    },
    {
      "id": "487",
      "question": "A company seeks a storage solution for its a pplication. The solution must be highly a vailable a nd scalable. The solution a lso must function a s a File system be mountable by multiple Linux instances in A WS a nd on premises through native protocols, a nd have no minimum size requirements. The company has set up a Site-to-Site VPN for a ccess from its on-premises network to its VPC. Which storage solution meets these requirements?",
      "options": {
        "A": "A mazon FSx Multi-A Z deployments",
        "B": "A mazon Elastic Block Store (A mazon EBS) Multi-A ttach volumes",
        "C": "A mazon Elastic File System (A mazon EFS) with multiple mount targets",
        "D": "A mazon Elastic File System (A mazon EFS) with a single mount target a nd multiple a ccess points"
      },
      "correct_answer": "C",
      "explanation": "A mazon EFS is a scalable file storage service that can be mounted by multiple A mazon EC2 instances a nd on-premises servers.\nIt provides a shared file system with multiple mount targets in different A vailability Zones (A Zs) for high a vailability.\nMultiple mount targets a llow you to mount the file system from different subnets, ensuring that instances in different network segments can a ccess the file system."
    },
    {
      "id": "488",
      "question": "A 4-year-old media company is using the A WS Organizations a ll features feature set to organize its A WS a ccounts. A ccording to the company's Finance team, the billing information on the member a ccounts must not be a ccessible to a nyone, including the root user of the member a ccounts. Which solution will meet these requirements?",
      "options": {
        "A": "A dd a ll Finance team users to a n IAM group. A ttach a n A WS managed policy named Billing to the group.",
        "B": "A ttach a n identity-based policy to deny a ccess to the billing information to a ll users, including the root user.",
        "C": "Create a service control policy (SCP) to deny a ccess to the billing information. A ttach the SCP to the root organizational unit (OU).",
        "D": "Convert from the Organizations a ll features feature set to the Organizations consolidated billing feature set."
      },
      "correct_answer": "C",
      "explanation": "SCPs in A WS Organizations a llow you to set fine-grained permissions a nd controls over what a ctions can be performed in member a ccounts.\nBy creating a n SCP, you can explicitly deny a ccess to billing information for a ll users, including the root user, under the specified organizational unit (OU)."
    },
    {
      "id": "489",
      "question": "A n ecommerce company runs a n a pplication in the A WS Cloud that is integrated with a n on-premises warehouse solution. The company uses A mazon Simple Notification Service (A mazon SNS) to send order messages to a n on-premises HTTPS endpoint so the warehouse a pplication can process the orders. The local data center team has detected that some of the order messages were not received. A solutions a rchitect needs to retain messages that a re not delivered a nd a nalyze the messages for up to 14 days. Which solution will meet these requirements with the LEAST development effort?",
      "options": {
        "A": "Configure a n A mazon SNS dead letter queue that has a n A mazon Kinesis Data Stream target with a retention period of 14 days.",
        "B": "A dd a n A mazon Simple Queue Service (A mazon SQS) queue with a retention period of 14 days between the a pplication a nd A mazon SNS.",
        "C": "Configure a n A mazon SNS dead letter queue that has a n A mazon Simple Queue Service (A mazon SQS) target with a retention period of 14 days.",
        "D": "Configure a n A mazon SNS dead letter queue that has a n A mazon DynamoDB target with a TTL a ttribute set for a retention period of 14 days."
      },
      "correct_answer": "C",
      "explanation": "A mazon SNS a llows you to set up a dead letter queue to capture a nd retain messages that cannot be delivered to the intended endpoint.\nWhen configuring a DLQ, you can specify a n A mazon SQS queue a s the target for messages that fail to be delivered.\nA mazon SQS provides message retention settings, a nd in this case, you can set the retention period to 14 days."
    },
    {
      "id": "490",
      "question": "A gaming company uses A mazon DynamoDB to store user information such a s geographic location, player data, a nd leaderboards. The company needs to configure continuous backups to a n A mazon S3 bucket with a minimal a mount of coding. The backups must not a ffect a vailability of the a pplication a nd must not a ffect the read capacity units (RCUs) that a re defined for the table. Which solution meets these requirements?",
      "options": {
        "A": "Use a n A mazon EMR cluster. Create a n A pache Hive job to back up the data to A mazon S3.",
        "B": "Export the data directly from DynamoDB to A mazon S3 with continuous backups. Turn on point-in-time recovery for the table.",
        "C": "Configure A mazon DynamoDB Streams. Create a n A WS Lambda function to consume the stream a nd export the data to a n A mazon S3 bucket.",
        "D": "Create a n A WS Lambda function to export the data from the database tables to A mazon S3 on a regular basis. Turn on point-in-time recovery for the table."
      },
      "correct_answer": "B",
      "explanation": ""
    },
    {
      "id": "491",
      "question": "A solutions a rchitect is designing a n a synchronous a pplication to process credit card data validation requests for a bank. The a pplication must be secure a nd be a ble to process each request a t least once. Which solution will meet these requirements MOST cost-effectively?",
      "options": {
        "A": "Use A WS Lambda event source mapping. Set A mazon Simple Queue Service (A mazon SQS) standard queues a s the event source. Use A WS Key Management Service (SSE-KMS) for encryption. A dd the kms:Decrypt permission for the Lambda execution role.",
        "B": "Use A WS Lambda event source mapping. Use A mazon Simple Queue Service (A mazon SQS) FIFO queues a s the event source. Use SQS managed encryption keys (SSE-SQS) for encryption. A dd the encryption key invocation permission for the Lambda function.",
        "C": "Use the A WS Lambda event source mapping. Set A mazon Simple Queue Service (A mazon SQS) FIFO queues a s the event source. Use A WS KMS keys (SSE-KMS). A dd the kms:Decrypt permission for the Lambda execution role.",
        "D": "Use the A WS Lambda event source mapping. Set A mazon Simple Queue Service (A mazon SQS) standard queues a s the event source. Use A WS KMS keys (SSE-KMS) for encryption. A dd the encryption key invocation permission for the Lambda function."
      },
      "correct_answer": "A",
      "explanation": ""
    },
    {
      "id": "492",
      "question": "A company has multiple A WS a ccounts for development work. Some staff consistently use oversized A mazon EC2 instances, which causes the company to exceed the yearly budget for the development a ccounts. The company wants to centrally restrict the creation of A WS resources in these a ccounts. Which solution will meet these requirements with the LEAST development effort?",
      "options": {
        "A": "Develop A WS Systems Manager templates that use a n a pproved EC2 creation process. Use the a pproved Systems Manager templates to provision EC2 instances.",
        "B": "Use A WS Organizations to organize the a ccounts into organizational units (OUs). DeFine a nd a ttach a service control policy (SCP) to control the usage of EC2 instance types.",
        "C": "Configure a n A mazon EventBridge rule that invokes a n A WS Lambda function when a n EC2 instance is created. Stop disallowed EC2 instance types.",
        "D": "Set up A WS Service Catalog products for the staff to create the a llowed EC2 instance types. Ensure that staff can deploy EC2 instances only by using the Service Catalog products."
      },
      "correct_answer": "B",
      "explanation": "A WS Organizations a llows you to consolidate multiple A WS a ccounts into a n organization that you create a nd centrally manage.\nOrganizational Units (OUs) can be used to group a ccounts based on different criteria, such a s development, production, etc.\nService Control Policies (SCPs) a re used to set fine-grained permissions on A WS a ccounts within a n organization.\nBy defining a n SCP a nd a ttaching it to the OUs containing the development a ccounts, you can restrict the EC2 instance types that can be launched."
    },
    {
      "id": "493",
      "question": "A company wants to use a rtificial intelligence (A I) to determine the quality of its customer service calls. The company currently manages calls in four different languages, including English. The company will offer new languages in the future. The company does not have the resources to regularly maintain machine learning (ML) models. The company needs to create written sentiment a nalysis reports from the customer service call recordings. The customer service call recording text must be translated into English. Which combination of steps will meet these requirements? (Choose three.)",
      "options": {
        "A": "Use A mazon Comprehend to translate the a udio recordings into English.",
        "B": "Use A mazon Lex to create the written sentiment a nalysis reports.",
        "C": "Use A mazon Polly to convert the a udio recordings into text.",
        "D": "Use A mazon Transcribe to convert the a udio recordings in a ny language into text.",
        "E": "Use A mazon Translate to translate text in a ny language to English. F. Use A mazon Comprehend to create the sentiment a nalysis reports."
      },
      "correct_answer": "D",
      "explanation": "E. Use A mazon Translate to translate text in a ny language to English.\nF. Use A mazon Comprehend to create the sentiment a nalysis reports.\nUse A mazon Transcribe to Convert A udio Recordings into Text:\nA mazon Transcribe is a service that converts speech into text. Use it to transcribe the customer service call recordings into text.\nUse A mazon Translate to Translate Text into English:\nA mazon Translate is a service that provides language translation. A fter transcribing the call recordings into text, use A mazon Translate to translate the text into English.\nUse A mazon Comprehend to Create Sentiment A nalysis Reports:\nA mazon Comprehend can be used for sentiment a nalysis, which involves determining the sentiment or emotion expressed in the text. A fter translating the text into English, use A mazon Comprehend to a nalyze the sentiment a nd create sentiment a nalysis reports."
    },
    {
      "id": "494",
      "question": "A company uses A mazon EC2 instances to host its internal systems. A s part of a deployment operation, a n a dministrator tries to use the A WS CLI to terminate a n EC2 instance. However, the a dministrator receives a 403 (A ccess Denied) error message. The a dministrator is using a n IAM role that has the following IAM policy a ttached: What is the cause of the unsuccessful request?",
      "options": {
        "A": "The EC2 instance has a resource-based policy with a Deny statement.",
        "B": "The principal has not been speciFied in the policy statement.",
        "C": "The \"A ction\" Field does not grant the a ctions that a re required to terminate the EC2 instance.",
        "D": "The request to terminate the EC2 instance does not originate from the CIDR blocks 192.0.2.0/24 or 203.0.113.0/24."
      },
      "correct_answer": "D",
      "explanation": ""
    },
    {
      "id": "495",
      "question": "A company is conducting a n internal a udit. The company wants to ensure that the data in a n A mazon S3 bucket that is a ssociated with the company\u2019s A WS Lake Formation data lake does not contain sensitive customer or employee data. The company wants to discover personally identifiable information (PII) or Financial information, including passport numbers a nd credit card numbers. Which solution will meet these requirements?",
      "options": {
        "A": "Configure A WS A udit Manager on the a ccount. Select the Payment Card Industry Data Security Standards (PCI DSS) for a uditing.",
        "B": "Configure A mazon S3 Inventory on the S3 bucket Configure A mazon A thena to query the inventory.",
        "C": "Configure A mazon Macie to run a data discovery job that uses managed identiFiers for the required data types.",
        "D": "Use A mazon S3 Select to run a report a cross the S3 bucket."
      },
      "correct_answer": "C",
      "explanation": "A mazon Macie is a security service that uses machine learning to a utomatically discover, classify, a nd protect sensitive data like PII or financial information.\nBy configuring A mazon Macie to run a data discovery job, you can use managed identifiers to search for specific types of sensitive data within the S3 bucket."
    },
    {
      "id": "496",
      "question": "A company uses on-premises servers to host its a pplications. The company is running out of storage capacity. The a pplications use both block storage a nd NFS storage. The company needs a high-performing solution that supports local caching without re-a rchitecting its existing a pplications. Which combination of a ctions should A solutions a rchitect take to meet these requirements? (Choose two.)",
      "options": {
        "A": "Mount A mazon S3 a s a File system to the on-premises servers.",
        "B": "Deploy a n A WS Storage Gateway File gateway to replace NFS storage.",
        "C": "Deploy A WS Snowball Edge to provision NFS mounts to on-premises servers.",
        "D": "Deploy a n A WS Storage Gateway volume gateway to replace the block storage.",
        "E": "Deploy A mazon Elastic File System (A mazon EFS) volumes a nd mount them to on-premises servers."
      },
      "correct_answer": "BD",
      "explanation": "D. Deploy a n A WS Storage Gateway volume gateway to replace the block storage."
    },
    {
      "id": "497",
      "question": "A company has a service that reads a nd writes large a mounts of data from a n A mazon S3 bucket in the same A WS Region. The service is deployed on A mazon EC2 instances within the private subnet of a VPC. The service communicates with A mazon S3 over a NAT gateway in the public subnet. However, the company wants a solution that will reduce the data output costs. Which solution will meet these requirements MOST cost-effectively?",
      "options": {
        "A": "Provision a dedicated EC2 NAT instance in the public subnet. Configure the route table for the private subnet to use the elastic network interface of this instance a s the destination for a ll S3 traffic.",
        "B": "Provision a dedicated EC2 NAT instance in the private subnet. Configure the route table for the public subnet to use the elastic network interface of this instance a s the destination for a ll S3 traffic.",
        "C": "Provision a VPC gateway endpoint. Configure the route table for the private subnet to use the gateway endpoint a s the route for a ll S3 traffic.",
        "D": "Provision a second NAT gateway. Configure the route table for the private subnet to use this NAT gateway a s the destination for a ll S3 traffic."
      },
      "correct_answer": "C",
      "explanation": ""
    },
    {
      "id": "498",
      "question": "A company uses A mazon S3 to store high-resolution pictures in a n S3 bucket. To minimize a pplication changes, the company stores the pictures a s the latest version of a n S3 object. The company needs to retain only the two most recent versions of the pictures. The company wants to reduce costs. The company has identified the S3 bucket a s a large expense. Which solution will reduce the S3 costs with the LEAST operational overhead?",
      "options": {
        "A": "Use S3 Lifecycle to delete expired object versions a nd retain the two most recent versions.",
        "B": "Use a n A WS Lambda function to check for older versions a nd delete a ll but the two most recent versions.",
        "C": "Use S3 Batch Operations to delete noncurrent object versions a nd retain only the two most recent versions.",
        "D": "Deactivate versioning on the S3 bucket a nd retain the two most recent versions."
      },
      "correct_answer": "A",
      "explanation": "This a pproach a llows you to a utomate the deletion of object versions based on lifecycle policies, reducing manual intervention a nd operational overhead."
    },
    {
      "id": "499",
      "question": "A company needs to minimize the cost of its 1 Gbps A WS Direct Connect connection. The company's a verage connection utilization is less than 10%. A solutions a rchitect must recommend a solution that will reduce the cost without compromising security. Which solution will meet these requirements?",
      "options": {
        "A": "Set up a new 1 Gbps Direct Connect connection. Share the connection with a nother A WS a ccount.",
        "B": "Set up a new 200 Mbps Direct Connect connection in the A WS Management Console.",
        "C": "Contact a n A WS Direct Connect Partner to order a 1 Gbps connection. Share the connection with a nother A WS a ccount.",
        "D": "Contact a n A WS Direct Connect Partner to order a 200 Mbps hosted connection for a n existing A WS a ccount."
      },
      "correct_answer": "D",
      "explanation": ""
    },
    {
      "id": "500",
      "question": "A company has multiple Windows File servers on premises. The company wants to migrate a nd consolidate its Files into a n A mazon FSx for Windows File Server File system. File permissions must be preserved to ensure that a ccess rights do not change. Which solutions will meet these requirements? (Choose two.)",
      "options": {
        "A": "Deploy A WS DataSync a gents on premises. Schedule DataSync tasks to transfer the data to the FSx for Windows File Server File system.",
        "B": "Copy the shares on each File server into A mazon S3 buckets by using the A WS CLI. Schedule A WS DataSync tasks to transfer the data to the FSx for Windows File Server File system.",
        "C": "Remove the drives from each File server. Ship the drives to A WS for import into A mazon S3. Schedule A WS DataSync tasks to transfer the data to the FSx for Windows File Server File system.",
        "D": "Order a n A WS Snowcone device. Connect the device to the on-premises network. Launch A WS DataSync a gents on the device. Schedule DataSync tasks to transfer the data to the FSx for Windows File Server File system.",
        "E": "Order a n A WS Snowball Edge Storage Optimized device. Connect the device to the on-premises network. Copy data to the device by using the A WS CLI. Ship the device back to A WS for import into A mazon S3. Schedule A WS DataSync tasks to transfer the data to the FSx for Windows File Server File system."
      },
      "correct_answer": "AD",
      "explanation": "D. Order a n A WS Snowcone device. Connect the device to the on-premises network. Launch A WS DataSync a gents on the device. Schedule DataSync tasks to transfer the data to the FSx for Windows File Server file system."
    }
  ]
}