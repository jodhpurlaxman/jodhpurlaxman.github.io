{
  "questions": [
    {
      "id": "201",
      "question": "A company is developing amarketing communications service that targets mobile app users. The company needs to send confirmation messages with Short Message Service (SMS) to its users. The users must be able to reply to the SMS messages. The company must store the responses for ayear for analysis. What should A solutions architect do to meet these requirements?",
      "options": {
        "A": "Create an A mazon Connect contact Flow to send the SMS messages. Use A WS Lambda to process the responses.",
        "B": "Build an A mazon Pinpoint journey. Configure A mazon Pinpoint to send events to an A mazon Kinesis data stream for analysis and archiving.",
        "C": "Use A mazon Simple Queue Service (A mazon SQS) to distribute the SMS messages. Use A WS Lambda to process the responses.",
        "D": "Create an A mazon Simple Notification Service (A mazon SNS) FIFO topic. Subscribe an A mazon Kinesis data stream to the SNS topic for analysis and archiving."
      },
      "correct_answer": "B",
      "explanation": "A mazon Pinpoint is a fully managed service for sending messages to mobile app users. With A mazon Pinpoint journeys, you can create multi-step campaigns to engage with users. By configuring A mazon Pinpoint to send events to an A mazon Kinesis data stream, you can capture the responses for further analysis and archiving. This solution provides a comprehensive approach to managing SMS messages and their responses in a scalable and efficient manner."
    },
    {
      "id": "202",
      "question": "A company is planning to move its data to an A mazon S3 bucket. The data must be encrypted when it is stored in the S3 bucket. A dditionally, the encryption key must be automatically rotated every year. Which solution will meet these requirements with the LEAST operational overhead?",
      "options": {
        "A": "Move the data to the S3 bucket. Use server-side encryption with A mazon S3 managed encryption keys (SSE-S3). Use the built-in key rotation behavior of SSE-S3 encryption keys.",
        "B": "Create an A WS Key Management Service (A WS KMS) customer managed key. Enable automatic key rotation. Set the S3 bucket\u2019s default encryption behavior to use the customer managed KMS key. Move the data to the S3 bucket.",
        "C": "Create an A WS Key Management Service (A WS KMS) customer managed key. Set the S3 bucket\u2019s default encryption behavior to use the customer managed KMS key. Move the data to the S3 bucket. Manually rotate the KMS key every year.",
        "D": "Encrypt the data with customer key material before moving the data to the S3 bucket. Create an A WS Key Management Service (A WS KMS) key without key material. Import the customer key material into the KMS key. Enable automatic key rotation."
      },
      "correct_answer": "B",
      "explanation": "In this option, you use A WS KMS to create a customer managed key, enable automatic key rotation, and set it as the default encryption key for the S3 bucket. This ensures that the data is encrypted with a key managed by A WS KMS, and the key rotation is handled automatically. This approach minimizes manual intervention and provides a secure and automated solution for data encryption with key rotation."
    },
    {
      "id": "203",
      "question": "The customers of aFinance company request appointments with Financial advisors by sending text messages. A web application that runs on A mazon EC2 instances accepts the appointment requests. The text messages are published to an A mazon Simple Queue Service (A mazon SQS) queue through the web application. A nother application that runs on EC2 instances then sends meeting invitations and meeting confirmation email messages to the customers. A fter successful scheduling, this application stores the meeting information in an A mazon DynamoDB database. A s the company expands, customers report that their meeting invitations are taking longer to arrive. What should A solutions architect recommend to resolve this issue?",
      "options": {
        "A": "A dd a DynamoDB A ccelerator (DAX) cluster in front of the DynamoDB database.",
        "B": "A dd an A mazon A PI Gateway A PI in front of the web application that accepts the appointment requests.",
        "C": "A dd an A mazon CloudFront distribution. Set the origin as the web application that accepts the appointment requests.",
        "D": "A dd an A uto Scaling group for the application that sends meeting invitations. Configure the A uto Scaling group to scale based on the depth of the SQS queue."
      },
      "correct_answer": "D",
      "explanation": "To resolve the issue of longer delivery times for meeting invitations, the solutions architect can recommend adding an A uto Scaling group for the application that sends meeting invitations and configuring the A uto Scaling group to scale based on the depth of the SQS queue. This will allow the application to scale up as the number of appointment requests increases, improving the performance and delivery times of the meeting invitations."
    },
    {
      "id": "204",
      "question": "A n online retail company has more than 50 million active customers and receives more than 25,000 orders each day. The company collects purchase data for customers and stores this data in A mazon S3. A dditional customer data is stored in A mazon RDS. The company wants to make all the data available to various teams so that the teams can perform analytics. The solution must provide the ability to manage Fine-grained permissions for the data and must minimize operational overhead. Which solution will meet these requirements?",
      "options": {
        "A": "Migrate the purchase data to write directly to A mazon RDS. Use RDS access controls to limit access.",
        "B": "Schedule an A WS Lambda function to periodically copy data from A mazon RDS to A mazon S3. Create an A WS Glue crawler. Use A mazon A thena to query the data. Use S3 policies to limit access.",
        "C": "Create a data lake by using A WS Lake Formation. Create an A WS Glue JDBC connection to A mazon RDS. Register the S3 bucket in Lake Formation. Use Lake Formation access controls to limit access.",
        "D": "Create an A mazon Redshift cluster. Schedule an A WS Lambda function to periodically copy data from A mazon S3 and A mazon RDS to A mazon Redshift. Use A mazon Redshift access controls to limit access."
      },
      "correct_answer": "C",
      "explanation": "A WS Lake Formation is designed to create a secure and scalable data lake in A mazon S3. By creating a data lake with Lake Formation, you can centrally manage access controls, fine-grained permissions, and define granular data access policies. This simplifies the process of granting and managing permissions for various teams.\nIn this scenario, you can use A WS Glue to create a JDBC connection to A mazon RDS for accessing the additional customer data. The S3 bucket, where the purchase data is stored, can be registered in Lake Formation. Lake Formation allows you to set up fine-grained access controls and permissions, providing the ability to manage who can access specific data within the data lake."
    },
    {
      "id": "205",
      "question": "A company hosts amarketing website in an on-premises data center. The website consists of static documents and runs on a single server. A n administrator updates the website content infrequently and uses an SFTP client to upload new documents. The company decides to host its website on A WS and to use A mazon Cloudfront. The company\u2019s solutions architect creates aCloudfront distribution. The solutions architect must design the most cost-effective and resilient architecture for website hosting to serve as the Cloudfront origin. Which solution will meet these requirements?",
      "options": {
        "A": "Create a virtual server by using A mazon Lightsail. Configure the web server in the Lightsail instance. Upload website content by using an SFTP client.",
        "B": "Create an A WS A uto Scaling group for A mazon EC2 instances. Use an A pplication Load Balancer. Upload website content by using an SFTP client.",
        "C": "Create a private A mazon S3 bucket. Use an S3 bucket policy to allow access from a CloudFront origin access identity (OAI). Upload website content by using the A WS CLI.",
        "D": "Create a public A mazon S3 bucket. Configure A WS Transfer for SFTP. Configure the S3 bucket for website hosting. Upload website content by using the SFTP client."
      },
      "correct_answer": "C",
      "explanation": "This option leverages A mazon S3 as the origin for CloudFront. By creating a private S3 bucket and using a bucket policy to allow access from a CloudFront origin access identity (OAI), you ensure that the content is served securely from S3 and that only CloudFront can access the bucket."
    },
    {
      "id": "206",
      "question": "A company wants to manage A mazon Machine Images (A MIs). The company currently copies A MIs to the same A WS Region where the A MIs were created. The company needs to design an application that captures A WS A PI calls and sends alerts whenever the A mazon EC2 Createimage A PI operation is called within the company\u2019s account. Which solution will meet these requirements with the LEAST operational overhead?",
      "options": {
        "A": "Create an A WS Lambda function to query A WS CloudTrail logs and to send an alert when a CreateImage A PI call is detected.",
        "B": "Configure A WS CloudTrail with an A mazon Simple Notification Service (A mazon SNS) notiFication that occurs when updated logs are sent to A mazon S3. Use A mazon A thena to create a new table and to query on CreateImage when an A PI call is detected.",
        "C": "Create an A mazon EventBridge (A mazon CloudWatch Events) rule for the CreateImage A PI call. Configure the target as an A mazon Simple Notification Service (A mazon SNS) topic to send an alert when a CreateImage A PI call is detected.",
        "D": "Configure an A mazon Simple Queue Service (A mazon SQS) FIFO queue as a target for A WS CloudTrail logs. Create an A WS Lambda function to send an alert to an A mazon Simple Notification Service (A mazon SNS) topic when a CreateImage A PI call is detected."
      },
      "correct_answer": "C",
      "explanation": "A mazon EventBridge (formerly CloudWatch Events) provides a simple and efficient way to respond to events in A WS services. By creating an EventBridge rule specifically for the CreateImage A PI call, you can easily configure an SNS topic as the target to send alerts when the event is detected."
    },
    {
      "id": "207",
      "question": "A company owns an asynchronous A PI that is used to ingest user requests and, based on the request type, dispatch requests to the appropriate microservice for processing. The company is using A mazon A PI Gateway to deploy the A PI front end, and an A WS Lambda function that invokes A mazon DynamoDB to store user requests before dispatching them to the processing microservices. The company provisioned as much DynamoDB throughput as its budget allows, but the company is still experiencing availability issues and is losing user requests. What should A solutions architect do to address this issue without impacting existing users?",
      "options": {
        "A": "A dd throttling on the A PI Gateway with server-side throttling limits.",
        "B": "Use DynamoDB A ccelerator (DAX) and Lambda to buffer writes to DynamoDB.",
        "C": "Create a secondary index in DynamoDB for the table with the user requests.",
        "D": "Use the A mazon Simple Queue Service (A mazon SQS) queue and Lambda to buffer writes to DynamoDB."
      },
      "correct_answer": "D",
      "explanation": ""
    },
    {
      "id": "208",
      "question": "A company needs to move data from an A mazon EC2 instance to an A mazon S3 bucket. The company must ensure that no A PI calls and no data are routed through public internet routes. Only the EC2 instance can have access to upload data to the S3 bucket. Which solution will meet these requirements?",
      "options": {
        "A": "Create an interface VPC endpoint for A mazon S3 in the subnet where the EC2 instance is located. A ttach a resource policy to the S3 bucket to only allow the EC2 instance\u2019s IAM role for access.",
        "B": "Create a gateway VPC endpoint for A mazon S3 in the A vailability Zone where the EC2 instance is located. A ttach appropriate security groups to the endpoint. A ttach a resource policy to the S3 bucket to only allow the EC2 instance\u2019s IAM role for access.",
        "C": "Run the nslookup tool from inside the EC2 instance to obtain the private IP address of the S3 bucket\u2019s service A PI endpoint. Create a route in the VPC route table to provide the EC2 instance with access to the S3 bucket. A ttach a resource policy to the S3 bucket to only allow the EC2 instance\u2019s IAM role for access.",
        "D": "Use the A WS provided, publicly available ip-ranges.json File to obtain the private IP address of the S3 bucket\u2019s service A PI endpoint. Create a route in the VPC route table to provide the EC2 instance with access to the S3 bucket. A ttach a resource policy to the S3 bucket to only allow the EC2 instance\u2019s IAM role for access."
      },
      "correct_answer": "A",
      "explanation": "Interface VPC endpoints for A mazon S3 (powered by A WS PrivateLink) allow communication between resources in your VPC and A mazon S3 without relying on public internet routes. It provides a secure and private connection.\nBy creating an interface VPC endpoint for A mazon S3 in the subnet where the EC2 instance is located, you ensure that the data doesn't travel over the public internet.\nA ttaching a resource policy to the S3 bucket allows you to control access and restrict it to the IAM role associated with the EC2 instance, ensuring only authorized entities can upload data to the bucket."
    },
    {
      "id": "209",
      "question": "A solutions architect is designing the architecture of a new application being deployed to the A WS Cloud. The application will run on A mazon EC2 On-Demand Instances and will automatically scale across multiple A vailability Zones. The EC2 instances will scale up and down frequently throughout the day. A n A pplication Load Balancer (A LB) will handle the load distribution. The architecture needs to support distributed session data management. The company is willing to make changes to code if needed. What should the solutions architect do to ensure that the architecture supports distributed session data management?",
      "options": {
        "A": "Use A mazon ElastiCache to manage and store session data.",
        "B": "Use session affinity (sticky sessions) of the A LB to manage session data.",
        "C": "Use Session Manager from A WS Systems Manager to manage the session.",
        "D": "Use the GetSessionToken A PI operation in A WS Security Token Service (A WS STS) to manage the session."
      },
      "correct_answer": "A",
      "explanation": "A mazon ElastiCache is a fully managed, in-memory data store service. It is commonly used for caching and session management in distributed applications.\nBy utilizing ElastiCache for session data management, you can store and retrieve session data in a scalable and high-performance manner.\nThe use of ElastiCache allows for a distributed and shared data store for session management across multiple instances and A vailability Zones."
    },
    {
      "id": "210",
      "question": "A company offers afood delivery service that is growing rapidly. Because of the growth, the company\u2019s order processing system is experiencing scaling problems during peak traffic hours. The current architecture includes the following: \u2022 A group of A mazon EC2 instances that run in an A mazon EC2 A uto Scaling group to collect orders from the application \u2022 A nother group of EC2 instances that run in an A mazon EC2 A uto Scaling group to fulfill orders The order collection process occurs quickly, but the order fulfillment process can take longer. Data must not be lost because of ascaling event. A solutions architect must ensure that the order collection process and the order fulfillment process can both scale properly during peak traffic hours. The solution must optimize utilization of the company\u2019s A WS resources. Which solution meets these requirements?",
      "options": {
        "A": "Use A mazon CloudWatch metrics to monitor the CPU of each instance in the A uto Scaling groups. Configure each A uto Scaling group\u2019s minimum capacity according to peak workload values.",
        "B": "Use A mazon CloudWatch metrics to monitor the CPU of each instance in the A uto Scaling groups. Configure a CloudWatch alarm to invoke an A mazon Simple Notification Service (A mazon SNS) topic that creates additional A uto Scaling groups on demand.",
        "C": "Provision two A mazon Simple Queue Service (A mazon SQS) queues: one for order collection and another for order fulFillment. Configure the EC2 instances to poll their respective queue. Scale the A uto Scaling groups based on notiFications that the queues send.",
        "D": "Provision two A mazon Simple Queue Service (A mazon SQS) queues: one for order collection and another for order fulFillment. Configure the EC2 instances to poll their respective queue. Create a metric based on a backlog per instance calculation. Scale the A uto Scaling groups based on this metric."
      },
      "correct_answer": "D",
      "explanation": ""
    },
    {
      "id": "211",
      "question": "A company hosts multiple production applications. One of the applications consists of resources from A mazon EC2, A WS Lambda, A mazon RDS, A mazon Simple Notification Service (A mazon SNS), and A mazon Simple Queue Service (A mazon SQS) across multiple A WS Regions. A ll company resources are tagged with atag name of \u201capplication\u201d and avalue that corresponds to each application. A solutions architect must provide the quickest solution for identifying all of the tagged components. Which solution meets these requirements?",
      "options": {
        "A": "Use A WS CloudTrail to generate a list of resources with the application tag.",
        "B": "Use the A WS CLI to query each service across all Regions to report the tagged components.",
        "C": "Run a query in A mazon CloudWatch Logs Insights to report on the components with the application tag.",
        "D": "Run a query with the A WS Resource Groups Tag Editor to report on the resources globally with the application tag."
      },
      "correct_answer": "D",
      "explanation": "A WS Resource Groups Tag Editor allows you to search and filter resources based on tags across multiple A WS Regions.\nIt provides a centralized view of resources and their corresponding tags, making it easier to identify and manage resources with specific tags.\nThis option provides a quick and efficient way to report on resources with the application tag globally."
    },
    {
      "id": "212",
      "question": "A company needs to export its database once aday to A mazon S3 for other teams to access. The exported object size varies between 2 GB and 5 GB. The S3 access pattern for the data is variable and changes rapidly. The data must be immediately available and must remain accessible for up to 3 months. The company needs the most cost-effective solution that will not increase retrieval time. Which S3 storage class should the company use to meet these requirements?",
      "options": {
        "A": "S3 Intelligent-Tiering",
        "B": "S3 Glacier Instant Retrieval",
        "C": "S3 Standard",
        "D": "S3 Standard-Infrequent A ccess (S3 Standard-IA)"
      },
      "correct_answer": "A",
      "explanation": "S3 Intelligent-Tiering is designed to optimize costs by automatically moving objects between two access tiers: frequent and infrequent access. It is suitable for data with unknown or changing access patterns.\nWith S3 Intelligent-Tiering, A mazon S3 automatically and transparently moves objects between access tiers based on changing access patterns. It is cost-effective for a wide range of storage access patterns.\nThe objects can be immediately accessed, and the storage cost is lower than using S3 Standard, making it a suitable choice for varying access patterns."
    },
    {
      "id": "213",
      "question": "A company is developing a new mobile app. The company must implement proper traffic Filtering to protect its A pplication Load Balancer (A LB) against common application-level attacks, such as cross-site scripting or SQL injection. The company has minimal infrastructure and operational staff. The company needs to reduce its share of the responsibility in managing, updating, and securing servers for its A WS environment. What should A solutions architect recommend to meet these requirements?",
      "options": {
        "A": "Configure A WS WAF rules and associate them with the A LB.",
        "B": "Deploy the application using A mazon S3 with public hosting enabled.",
        "C": "Deploy A WS Shield A dvanced and add the A LB as a protected resource.",
        "D": "Create a new A LB that directs traffic to an A mazon EC2 instance running a third-party Firewall, which then passes the traffic to the current A LB."
      },
      "correct_answer": "A",
      "explanation": "A WS WAF (Web A pplication Firewall) is a service that helps protect web applications from common web exploits by allowing you to define customizable web security rules. It can be associated with an A pplication Load Balancer (A LB) to filter and block malicious traffic before it reaches the application.\nA WS WAF is a managed service, which means it reduces the operational burden on the company by handling the infrastructure, updates, and security configurations."
    },
    {
      "id": "214",
      "question": "A company\u2019s reporting system delivers hundreds of .csv files to an A mazon S3 bucket each day. The company must convert these files to A pache Parquet format and must store the files in atransformed data bucket. Which solution will meet these requirements with the LEAST development effort?",
      "options": {
        "A": "Create an A mazon EMR cluster with A pache Spark installed. Write a Spark application to transform the data. Use EMR File System (EMRFS) to write files to the transformed data bucket.",
        "B": "Create an A WS Glue crawler to discover the data. Create an A WS Glue extract, transform, and load (ETL) job to transform the data. Specify the transformed data bucket in the output step.",
        "C": "Use A WS Batch to create a job deFinition with Bash syntax to transform the data and output the data to the transformed data bucket. Use the job deFinition to submit a job. Specify an array job as the job type.",
        "D": "Create an A WS Lambda function to transform the data and output the data to the transformed data bucket. Configure an event notiFication for the S3 bucket. Specify the Lambda function as the destination for the event notiFication."
      },
      "correct_answer": "B",
      "explanation": "A WS Glue is a fully managed extract, transform, and load (ETL) service that makes it easy to prepare and load data for analysis. In this scenario:\nThe A WS Glue crawler can automatically discover the schema of your data stored in A mazon S3, including the .csv files.\nThe A WS Glue ETL job allows you to define the transformation logic easily. You can create a job using a visual interface or script in Python/Spark.\nYou can specify the transformed data bucket as the output location for the ETL job."
    },
    {
      "id": "215",
      "question": "A company has 700 TB of backup data stored in network attached storage (NAS) in its data center. This backup data need to be accessible for infrequent regulatory requests and must be retained 7 years. The company has decided to migrate this backup data from its data center to A WS. The migration must be complete within 1 month. The company has 500 Mbps of dedicated bandwidth on its public internet connection available for data transfer. What should A solutions architect do to migrate and store the data at the LOWEST cost?",
      "options": {
        "A": "Order A WS Snowball devices to transfer the data. Use a lifecycle policy to transition the files to A mazon S3 Glacier Deep A rchive.",
        "B": "Deploy a VPN connection between the data center and A mazon VPC. Use the A WS CLI to copy the data from on premises to A mazon S3 Glacier.",
        "C": "Provision a 500 Mbps A WS Direct Connect connection and transfer the data to A mazon S3. Use a lifecycle policy to transition the files to A mazon S3 Glacier Deep A rchive.",
        "D": "Use A WS DataSync to transfer the data and deploy a DataSync agent on premises. Use the DataSync task to copy files from the on-premises NAS storage to A mazon S3 Glacier."
      },
      "correct_answer": "A",
      "explanation": ""
    },
    {
      "id": "216",
      "question": "A company has a serverless website with millions of objects in an A mazon S3 bucket. The company uses the S3 bucket as the origin for an A mazon Cloudfront distribution. The company did not set encryption on the S3 bucket before the objects were loaded. A solutions architect needs to enable encryption for all existing objects and for all objects that are added to the S3 bucket in the future. Which solution will meet these requirements with the LEAST amount of effort?",
      "options": {
        "A": "Create a new S3 bucket. Turn on the default encryption settings for the new S3 bucket. Download all existing objects to temporary local storage. Upload the objects to the new S3 bucket.",
        "B": "Turn on the default encryption settings for the S3 bucket. Use the S3 Inventory feature to create a .csv File that lists the unencrypted objects. Run an S3 Batch Operations job that uses the copy command to encrypt those objects.",
        "C": "Create a new encryption key by using A WS Key Management Service (A WS KMS). Change the settings on the S3 bucket to use server-side encryption with A WS KMS managed encryption keys (SSE-KMS). Turn on versioning for the S3 bucket.",
        "D": "Navigate to A mazon S3 in the A WS Management Console. Browse the S3 bucket\u2019s objects. Sort by the encryption Field. Select each unencrypted object. Use the Modify button to apply default encryption settings to every unencrypted object in the S3 bucket."
      },
      "correct_answer": "B",
      "explanation": "This option utilizes the S3 Inventory feature to generate a list of unencrypted objects in the S3 bucket. It then leverages S3 Batch Operations to perform a copy operation, allowing the encryption of the objects during the copy process. This approach is efficient and does not require downloading and re-uploading all existing objects."
    },
    {
      "id": "217",
      "question": "A company runs aglobal web application on A mazon EC2 instances behind an A pplication Load Balancer. The application stores data in A mazon A urora. The company needs to create adisaster recovery solution and can tolerate up to 30 minutes of downtime and potential data loss. The solution does not need to handle the load when the primary infrastructure is healthy. What should A solutions architect do to meet these requirements?",
      "options": {
        "A": "Deploy the application with the required infrastructure elements in place. Use A mazon Route 53 to conFigure active-passive failover. Create an A urora Replica in a second A WS Region.",
        "B": "Host a scaled-down deployment of the application in a second A WS Region. Use A mazon Route 53 to conFigure active-active failover. Create an A urora Replica in the second Region.",
        "C": "Replicate the primary infrastructure in a second A WS Region. Use A mazon Route 53 to conFigure active-active failover. Create an A urora database that is restored from the latest snapshot.",
        "D": "Back up data with A WS Backup. Use the backup to create the required infrastructure in a second A WS Region. Use A mazon Route 53 to conFigure active-passive failover. Create an A urora second primary instance in the second Region."
      },
      "correct_answer": "A",
      "explanation": ""
    },
    {
      "id": "218",
      "question": "A company has a web server running on an A mazon EC2 instance in a public subnet with an Elastic IP address. The default security group is assigned to the EC2 instance. The default network A CL has been modified to block all traffic. A solutions architect needs to make the web server accessible from everywhere on port 443. Which combination of steps will accomplish this task? (Choose two.)",
      "options": {
        "A": "Create a security group with a rule to allow TCP port 443 from source 0.0.0.0/0.",
        "B": "Create a security group with a rule to allow TCP port 443 to destination 0.0.0.0/0.",
        "C": "Update the network A CL to allow TCP port 443 from source 0.0.0.0/0.",
        "D": "Update the network A CL to allow inbound/outbound TCP port 443 from source 0.0.0.0/0 and to destination 0.0.0.0/0.",
        "E": "Update the network A CL to allow inbound TCP port 443 from source 0.0.0.0/0 and outbound TCP port 32768-65535 to destination 0.0.0.0/0."
      },
      "correct_answer": "AE",
      "explanation": "E. Update the network A CL to allow inbound TCP port 443 from source 0.0.0.0/0 and outbound TCP port 32768-65535 to destination 0.0.0.0/0."
    },
    {
      "id": "219",
      "question": "A company\u2019s application is having performance issues. The application is stateful and needs to complete in-memory tasks on A mazon EC2 instances. The company used A WS Cloudformation to deploy infrastructure and used the M5 EC2 instance family. A s traffic increased, the application performance degraded. Users are reporting delays when the users attempt to access the application. Which solution will resolve these issues in the MOST operationally eficient way?",
      "options": {
        "A": "Replace the EC2 instances with T3 EC2 instances that run in an A uto Scaling group. Make the changes by using the A WS Management Console.",
        "B": "Modify the CloudFormation templates to run the EC2 instances in an A uto Scaling group. Increase the desired capacity and the maximum capacity of the A uto Scaling group manually when an increase is necessary.",
        "C": "Modify the CloudFormation templates. Replace the EC2 instances with R5 EC2 instances. Use A mazon CloudWatch built-in EC2 memory metrics to track the application performance for future capacity planning.",
        "D": "Modify the CloudFormation templates. Replace the EC2 instances with R5 EC2 instances. Deploy the A mazon CloudWatch agent on the EC2 instances to generate custom application latency metrics for future capacity planning."
      },
      "correct_answer": "D",
      "explanation": ""
    },
    {
      "id": "220",
      "question": "A solutions architect is designing a new A PI using A mazon A PI Gateway that will receive requests from users. The volume of requests is highly variable; several hours can pass without receiving a single request. The data processing will take place asynchronously, but should be completed within afew seconds after arequest is made. Which compute service should the solutions architect have the A PI invoke to deliver the requirements at the lowest cost?",
      "options": {
        "A": "A n A WS Glue job",
        "B": "A n A WS Lambda function",
        "C": "A containerized service hosted in A mazon Elastic Kubernetes Service (A mazon EKS)",
        "D": "A containerized service hosted in A mazon ECS with A mazon EC2"
      },
      "correct_answer": "B",
      "explanation": "A WS Lambda supports asynchronous invocation, which is suitable for scenarios where data processing can take place independently of the A PI request and complete within a few seconds. This aligns with the requirement of processing data asynchronously."
    },
    {
      "id": "221",
      "question": "A company runs an application on agroup of A mazon Linux EC2 instances. For compliance reasons, the company must retain all application log files for 7 years. The log files will be analyzed by areporting tool that must be able to access all the files concurrently. Which storage solution meets these requirements MOST cost-effectively?",
      "options": {
        "A": "A mazon Elastic Block Store (A mazon EBS)",
        "B": "A mazon Elastic File System (A mazon EFS)",
        "C": "A mazon EC2 instance store",
        "D": "A mazon S3"
      },
      "correct_answer": "D",
      "explanation": "S3 is a highly durable and scalable object storage service. It is designed for high availability and can store large amounts of data. S3 is cost-effective for long-term storage, and its pricing is based on the amount of data stored."
    },
    {
      "id": "222",
      "question": "A company has hired an external vendor to perform work in the company\u2019s A WS account. The vendor uses an automated tool that is hosted in an A WS account that the vendor owns. The vendor does not have IAM access to the company\u2019s A WS account. How should A solutions architect grant this access to the vendor?",
      "options": {
        "A": "Create an IAM role in the company\u2019s account to delegate access to the vendor\u2019s IAM role. A ttach the appropriate IAM policies to the role for the permissions that the vendor requires.",
        "B": "Create an IAM user in the company\u2019s account with a password that meets the password complexity requirements. A ttach the appropriate IAM policies to the user for the permissions that the vendor requires.",
        "C": "Create an IAM group in the company\u2019s account. A dd the tool\u2019s IAM user from the vendor account to the group. A ttach the appropriate IAM policies to the group for the permissions that the vendor requires.",
        "D": "Create a new identity provider by choosing \u201cA WS account\u201d as the provider type in the IAM console. Supply the vendor\u2019s A WS account ID and user name. A ttach the appropriate IAM policies to the new provider for the permissions that the vendor requires."
      },
      "correct_answer": "A",
      "explanation": "IAM roles allow you to delegate access to resources in your A WS account to another A WS account. In this case, you can create a role in your account and grant the vendor's IAM role permission to assume that role.\nBy doing this, the vendor can use temporary security credentials obtained by assuming the role to access resources in your account. This ensures that the vendor doesn't need IAM credentials from your account."
    },
    {
      "id": "223",
      "question": "A company has deployed aJava Spring Boot application as apod that runs on A mazon Elastic Kubernetes Service (A mazon EKS) in private subnets. The application needs to write data to an A mazon DynamoDB table. A solutions architect must ensure that the application can interact with the DynamoDB table without exposing traffic to the internet. Which combination of steps should the solutions architect take to accomplish this goal? (Choose two.)",
      "options": {
        "A": "A ttach an IAM role that has suFicient privileges to the EKS pod.",
        "B": "A ttach an IAM user that has suFicient privileges to the EKS pod.",
        "C": "A llow outbound connectivity to the DynamoDB table through the private subnets\u2019 network A CLs.",
        "D": "Create a VPC endpoint for DynamoDB.",
        "E": "Embed the access keys in the Java Spring Boot code."
      },
      "correct_answer": "AD",
      "explanation": "D. Create a VPC endpoint for DynamoDB. Most Voted\nThis IAM role should have the necessary permissions to interact with DynamoDB. You can attach the IAM role to the pod using Kubernetes service account annotations or other mechanisms.\nBy creating a VPC endpoint for DynamoDB, you allow your EKS pods to access DynamoDB directly within the A WS network without traversing the public internet. This enhances security and reduces the risk of exposure."
    },
    {
      "id": "224",
      "question": "A company recently migrated its web application to A WS by rehosting the application on A mazon EC2 instances in a single A WS Region. The company wants to redesign its application architecture to be highly available and fault tolerant. traffic must reach all running EC2 instances randomly. Which combination of steps should the company take to meet these requirements? (Choose two.)",
      "options": {
        "A": "Create an A mazon Route 53 failover routing policy.",
        "B": "Create an A mazon Route 53 weighted routing policy.",
        "C": "Create an A mazon Route 53 multivalue answer routing policy.",
        "D": "Launch three EC2 instances: two instances in one A vailability Zone and one instance in another A vailability Zone.",
        "E": "Launch four EC2 instances: two instances in one A vailability Zone and two instances in another A vailability Zone."
      },
      "correct_answer": "CE",
      "explanation": ""
    },
    {
      "id": "225",
      "question": "A media company collects and analyzes user activity data on premises. The company wants to migrate this capability to A WS. The user activity data store will continue to grow and will be petabytes in size. The company needs to build a highly available data ingestion solution that facilitates on-demand analytics of existing data and new data with SQL. Which solution will meet these requirements with the LEAST operational overhead?",
      "options": {
        "A": "Send activity data to an A mazon Kinesis data stream. Configure the stream to deliver the data to an A mazon S3 bucket.",
        "B": "Send activity data to an A mazon Kinesis Data Firehose delivery stream. Configure the stream to deliver the data to an A mazon Redshift cluster.",
        "C": "Place activity data in an A mazon S3 bucket. Configure A mazon S3 to run an A WS Lambda function on the data as the data arrives in the S3 bucket.",
        "D": "Create an ingestion service on A mazon EC2 instances that are spread across multiple A vailability Zones. Configure the service to forward data to an A mazon RDS Multi-A Z database."
      },
      "correct_answer": "B",
      "explanation": "A mazon Kinesis Data Firehose: It is a fully managed service that simplifies the delivery of streaming data to destinations such as A mazon S3, A mazon Redshift, or A mazon Elasticsearch Service. It handles the scaling, buffering, and delivery of data.\nA mazon Redshift: It is a fully managed, petabyte-scale data warehouse service. It is optimized for high-performance analysis using standard SQL queries.\nLeast Operational Overhead: Kinesis Data Firehose takes care of many operational aspects, including scaling and buffering, reducing the operational overhead on your part. Configuring it to deliver data to A mazon Redshift provides a streamlined and managed solution."
    },
    {
      "id": "226",
      "question": "A company collects data from thousands of remote devices by using a RESTful web services application that runs on an A mazon EC2 instance. The EC2 instance receives the raw data, transforms the raw data, and stores all the data in an A mazon S3 bucket. The number of remote devices will increase into the millions soon. The company needs a highly scalable solution that minimizes operational overhead. Which combination of steps should A solutions architect take to meet these requirements? (Choose two.)",
      "options": {
        "A": "Use A WS Glue to process the raw data in A mazon S3.",
        "B": "Use A mazon Route 53 to route traffic to different EC2 instances.",
        "C": "A dd more EC2 instances to accommodate the increasing amount of incoming data.",
        "D": "Send the raw data to A mazon Simple Queue Service (A mazon SQS). Use EC2 instances to process the data.",
        "E": "Use A mazon A PI Gateway to send the raw data to an A mazon Kinesis data stream. Configure A mazon Kinesis Data Firehose to use the data stream as a source to deliver the data to A mazon S3."
      },
      "correct_answer": "AE",
      "explanation": "E. Use A mazon A PI Gateway to send the raw data to an A mazon Kinesis data stream. Configure A mazon Kinesis Data Firehose to use the data stream as a source to deliver the data to A mazon S3.\nA. It automatically discovers the schema of the data and generates ETL code to transform it.\nE. A PI Gateway can be used to receive the raw data from the remote devices via RESTful web services. It provides a scalable and managed infrastructure to handle the incoming requests. The data can then be sent to an A mazon Kinesis data stream, which is a highly scalable and durable real-time data streaming service. From there, A mazon Kinesis Data Firehose can be configured to use the data stream as a source and deliver the transformed data to A mazon S3. This combination of services allows for the seamless ingestion and processing of data while minimizing operational overhead."
    },
    {
      "id": "227",
      "question": "A company needs to retain its A WS Cloudtrail logs for 3 years. The company is enforcing Cloudtrail across aset of A WS accounts by using A WS Organizations from the parent account. The Cloudtrail target S3 bucket is configured with S3 Versioning enabled. A n S3 Lifecycle policy is in place to delete current objects after 3 years. A fter the fourth year of use of the S3 bucket, the S3 bucket metrics show that the number of objects has continued to rise. However, the number of new Cloudtrail logs that are delivered to the S3 bucket has remained consistent. Which solution will delete objects that are older than 3 years in the MOST cost-effective manner?",
      "options": {
        "A": "Configure the organization\u2019s centralized CloudTrail trail to expire objects after 3 years.",
        "B": "Configure the S3 Lifecycle policy to delete previous versions as well as current versions.",
        "C": "Create an A WS Lambda function to enumerate and delete objects from A mazon S3 that are older than 3 years.",
        "D": "Configure the parent account as the owner of all objects that are delivered to the S3 bucket."
      },
      "correct_answer": "B",
      "explanation": "S3 Lifecycle Policy: Enabling S3 versioning allows you to use a lifecycle policy to manage both current and previous versions of objects in the bucket. By configuring the S3 Lifecycle policy to delete objects older than 3 years, it will automatically delete both the current and previous versions that meet the specified criteria."
    },
    {
      "id": "228",
      "question": "A company has an A PI that receives real-time data from aFieet of monitoring devices. The A PI stores this data in an A mazon RDS DB instance for later analysis. The amount of data that the monitoring devices send to the A PI Fiuctuates. During periods of heavy traffic, the A PI often returns timeout errors. A fter an inspection of the logs, the company determines that the database is not capable of processing the volume of write traffic that comes from the A PI. A solutions architect must minimize the number of connections to the database and must ensure that data is not lost during periods of heavy traffic. Which solution will meet these requirements?",
      "options": {
        "A": "Increase the size of the DB instance to an instance type that has more available memory.",
        "B": "Modify the DB instance to be a Multi-A Z DB instance. Configure the application to write to all active RDS DB instances.",
        "C": "Modify the A PI to write incoming data to an A mazon Simple Queue Service (A mazon SQS) queue. Use an A WS Lambda function that A mazon SQS invokes to write data from the queue to the database.",
        "D": "Modify the A PI to write incoming data to an A mazon Simple Notification Service (A mazon SNS) topic. Use an A WS Lambda function that A mazon SNS invokes to write data from the topic to the database."
      },
      "correct_answer": "C",
      "explanation": "A mazon SQS: SQS is a fully managed message queuing service that decouples the components of a cloud application. It acts as a buffer between the A PI and the database, allowing for better handling of varying write traffic.\nA WS Lambda: Using Lambda to process the data from the SQS queue helps in efficiently managing the connection to the database. Lambda functions can be scaled automatically based on the incoming workload."
    },
    {
      "id": "229",
      "question": "A company manages its own A mazon EC2 instances that run MySQL databases. The company is manually managing replication and scaling as demand increases or decreases. The company needs a new solution that simplifies the process of adding or removing compute capacity to or from its database tier as needed. The solution also must offer improved performance, scaling, and durability with minimal effort from operations. Which solution meets these requirements?",
      "options": {
        "A": "Migrate the databases to A mazon A urora Serverless for A urora MySQL.",
        "B": "Migrate the databases to A mazon A urora Serverless for A urora PostgreSQL.",
        "C": "Combine the databases into one larger MySQL database. Run the larger database on larger EC2 instances.",
        "D": "Create an EC2 A uto Scaling group for the database tier. Migrate the existing databases to the new environment."
      },
      "correct_answer": "A",
      "explanation": "A mazon A urora Serverless: A urora Serverless is an on-demand, auto-scaling configuration for A mazon A urora. It automatically adjusts the database capacity based on actual consumption, enabling seamless scaling without manual intervention. It is a fully managed service, reducing operational overhead."
    },
    {
      "id": "230",
      "question": "A company is concerned that two NAT instances in use will no longer be able to support the traffic needed for the company\u2019s application. A solutions architect wants to implement a solution that is highly available, fault tolerant, and automatically scalable. What should the solutions architect recommend?",
      "options": {
        "A": "Remove the two NAT instances and replace them with two NAT gateways in the same A vailability Zone.",
        "B": "Use A uto Scaling groups with Network Load Balancers for the NAT instances in different A vailability Zones.",
        "C": "Remove the two NAT instances and replace them with two NAT gateways in different A vailability Zones.",
        "D": "Replace the two NAT instances with Spot Instances in different A vailability Zones and deploy a Network Load Balancer."
      },
      "correct_answer": "C",
      "explanation": "NAT Gateway: NAT Gateways are managed, highly available, and scalable components provided by A WS. They are designed to handle the network address translation for instances in private subnets. By deploying NAT gateways in different A vailability Zones, you ensure high availability.\nBenefits of NAT Gateway:\nManaged Service: NAT Gateway is a fully managed service, reducing operational overhead.\nHigh A vailability: Deploying NAT gateways in different A vailability Zones ensures fault tolerance and high availability.\nA utomatically Scalable: NAT Gateways automatically scale based on the traffic volume, eliminating the need for manual adjustments."
    },
    {
      "id": "231",
      "question": "A n application runs on an A mazon EC2 instance that has an Elastic IP address in VPC A. The application requires access to a database in VPC B. Both VPCs are in the same A WS account. Which solution will provide the required access MOST securely?",
      "options": {
        "A": "Create a DB instance security group that allows all traffic from the public IP address of the application server in VPC A.",
        "B": "Configure a VPC peering connection between VPC A and VPC B.",
        "C": "Make the DB instance publicly accessible. A ssign a public IP address to the DB instance.",
        "D": "Launch an EC2 instance with an Elastic IP address into VPC B. Proxy all requests through the new EC2 instance."
      },
      "correct_answer": "B",
      "explanation": "VPC peering allows direct connectivity between two VPCs. This solution enables communication between instances in VPC A and VPC B using private IP addresses. It does not require public IP addresses or the exposure of databases to the public internet."
    },
    {
      "id": "232",
      "question": "A company runs demonstration environments for its customers on A mazon EC2 instances. Each environment is isolated in its own VPC. The company\u2019s operations team needs to be notified when RDP or SSH access to an environment has been established.",
      "options": {
        "A": "Configure A mazon CloudWatch A pplication Insights to create A WS Systems Manager OpsItems when RDP or SSH access is detected.",
        "B": "Configure the EC2 instances with an IAM instance proFile that has an IAM role with the A mazonSSMManagedInstanceCore policy attached.",
        "C": "Publish VPC Flow logs to A mazon CloudWatch Logs. Create required metric Filters. Create an A mazon CloudWatch metric alarm with a notiFication action for when the alarm is in the A LARM state.",
        "D": "Configure an A mazon EventBridge rule to listen for events of type EC2 Instance State-change Notification. Configure an A mazon Simple Notification Service (A mazon SNS) topic as a target. Subscribe the operations team to the topic."
      },
      "correct_answer": "B",
      "explanation": "The correct option for notifying the operations team when RDP or SSH access to an environment has been established is:\nC. Publish VPC flow logs to A mazon CloudWatch Logs. Create required metric filters. Create an A mazon CloudWatch metric alarm with a notification action for when the alarm is in the A LARM state.\nHere's why:\nVPC Flow Logs:** VPC flow logs capture information about the IP traffic going to and from network interfaces in your VPC. This includes information about accepted and rejected connections. To monitor RDP or SSH access, you can analyze these logs.\nCloudWatch Logs:** By publishing VPC flow logs to CloudWatch Logs, you can analyze the logs using metric filters to extract relevant information.\nMetric Filters:** Create metric filters to match the patterns corresponding to RDP or SSH access in the CloudWatch Logs. For example, you can create metric filters that look for specific keywords or patterns related to RDP or SSH connections.\nCloudWatch Metric A larm:** Set up CloudWatch metric alarms based on the metric filters. When the alarm is triggered (indicating that RDP or SSH access has been detected), it can take a notification action, such as sending a notification to the operations team via A mazon SNS."
    },
    {
      "id": "233",
      "question": "A solutions architect has created a new A WS account and must secure A WS account root user access. Which combination of actions will accomplish this? (Choose two.)",
      "options": {
        "A": "Ensure the root user uses a strong password.",
        "B": "Enable multi-factor authentication to the root user.",
        "C": "Store root user access keys in an encrypted A mazon S3 bucket.",
        "D": "A dd the root user to a group containing administrative permissions.",
        "E": "A pply the required permissions to the root user with an inline policy document."
      },
      "correct_answer": "AB",
      "explanation": "B. Enable multi-factor authentication to the root user.\nUsing a strong, complex password for the root user is a fundamental security practice. This helps protect the account from unauthorized access.\nEnabling MFA adds an additional layer of security. Even if someone manages to obtain the root user's password, they would still need the second factor (e.g., a mobile device or hardware token) to successfully authenticate."
    },
    {
      "id": "234",
      "question": "A company is building a new web-based customer relationship management application. The application will use several A mazon EC2 instances that are backed by A mazon Elastic Block Store (A mazon EBS) volumes behind an A pplication Load Balancer (A LB). The application will also use an A mazon A urora database. A ll data for the application must be encrypted at rest and in transit. Which solution will meet these requirements?",
      "options": {
        "A": "Use A WS Key Management Service (A WS KMS) certiFicates on the A LB to encrypt data in transit. Use A WS CertiFicate Manager (A CM) to encrypt the EBS volumes and A urora database storage at rest.",
        "B": "Use the A WS root account to log in to the A WS Management Console. Upload the company\u2019s encryption certiFicates. While in the root account, select the option to turn on encryption for all data at rest and in transit for the account.",
        "C": "Use A WS Key Management Service (A WS KMS) to encrypt the EBS volumes and A urora database storage at rest. A ttach an A WS CertiFicate Manager (A CM) certiFicate to the A LB to encrypt data in transit.",
        "D": "Use BitLocker to encrypt all data at rest. Import the company\u2019s TLS certiFicate keys to A WS Key Management Service (A WS KMS) A ttach the KMS keys to the A LB to encrypt data in transit."
      },
      "correct_answer": "C",
      "explanation": "Using A WS KMS to encrypt EBS volumes and A urora database storage at rest is a good practice. You can specify a KMS key when creating these resources to ensure data encryption.\nA ttaching an A CM certificate to the A LB allows you to use HTTPS, which encrypts data in transit between clients and the A LB. This ensures secure communication over the network."
    },
    {
      "id": "235",
      "question": "A company is moving its on-premises Oracle database to A mazon A urora PostgreSQL. The database has several applications that write to the same tables. The applications need to be migrated one by one with amonth in between each migration. Management has expressed concerns that the database has a high number of reads and writes. The data must be kept in sync across both databases throughout the migration. What should A solutions architect recommend?",
      "options": {
        "A": "Use A WS DataSync for the initial migration. Use A WS Database Migration Service (A WS DMS) to create a change data capture (CDC) replication task and a table mapping to select all tables.",
        "B": "Use A WS DataSync for the initial migration. Use A WS Database Migration Service (A WS DMS) to create a full load plus change data capture (CDC) replication task and a table mapping to select all tables.",
        "C": "Use the A WS Schema Conversion Tool with A WS Database Migration Service (A WS DMS) using a memory optimized replication instance. Create a full load plus change data capture (CDC) replication task and a table mapping to select all tables.",
        "D": "Use the A WS Schema Conversion Tool with A WS Database Migration Service (A WS DMS) using a compute optimized replication instance. Create a full load plus change data capture (CDC) replication task and a table mapping to select the largest tables."
      },
      "correct_answer": "C",
      "explanation": ""
    },
    {
      "id": "236",
      "question": "A company has a three-tier application for image sharing. The application uses an A mazon EC2 instance for the front-end layer, another EC2 instance for the application layer, and athird EC2 instance for aMySQL database. A solutions architect must design ascalable and highly available solution that requires the least amount of change to the application. Which solution meets these requirements?",
      "options": {
        "A": "Use A mazon S3 to host the front-end layer. Use A WS Lambda functions for the application layer. Move the database to an A mazon DynamoDB table. Use A mazon S3 to store and serve users\u2019 images.",
        "B": "Use load-balanced Multi-A Z A WS Elastic Beanstalk environments for the front-end layer and the application layer. Move the database to an A mazon RDS DB instance with multiple read replicas to serve users\u2019 images.",
        "C": "Use A mazon S3 to host the front-end layer. Use a Fieet of EC2 instances in an A uto Scaling group for the application layer. Move the database to a memory optimized instance type to store and serve users\u2019 images.",
        "D": "Use load-balanced Multi-A Z A WS Elastic Beanstalk environments for the front-end layer and the application layer. Move the database to an A mazon RDS Multi-A Z DB instance. Use A mazon S3 to store and serve users\u2019 images."
      },
      "correct_answer": "D",
      "explanation": "A WS Elastic Beanstalk provides an easy way to deploy and manage applications. By using Multi-A Z environments, the front-end and application layers can automatically scale and provide high availability across multiple A vailability Zones (A Zs).\nA mazon RDS Multi-A Z DB Instance:\nMoving the database to an A mazon RDS Multi-A Z DB instance ensures high availability and automatic failover in the event of a failure in one A vailability Zone.\nA mazon S3 for Storing and Serving Images:\nUsing A mazon S3 for storing and serving users' images is a scalable and cost-effective solution. S3 is designed for high durability and availability, making it suitable for serving static content like images."
    },
    {
      "id": "237",
      "question": "A n application running on an A mazon EC2 instance in VPC-A needs to access files in another EC2 instance in VPC-B. Both VPCs are in separate A WS accounts. The network administrator needs to design a solution to configure secure access to EC2 instance in VPC-Bfrom VPC-A. The connectivity should not have a single point of failure or bandwidth concerns. Which solution will meet these requirements?",
      "options": {
        "A": "Set up a VPC peering connection between VPC-A and VPC-B.",
        "B": "Set up VPC gateway endpoints for the EC2 instance running in VPC-B.",
        "C": "A ttach a virtual private gateway to VPC-B and set up routing from VPC-A.",
        "D": "Create a private virtual interface (VIF) for the EC2 instance running in VPC-B and add appropriate routes from VPC-A."
      },
      "correct_answer": "A",
      "explanation": "A VPC peering connection allows secure communication between instances in different VPCs using private IP addresses without the need for internet gateways, VPN connections, or NAT devices. By setting it up, the application running in VPC-A can directly access the EC2 in VPC-B without going through the public internet or any single point of failure."
    },
    {
      "id": "238",
      "question": "A company wants to experiment with individual A WS accounts for its engineer team. The company wants to be notified as soon as the A mazon EC2 instance usage for agiven month exceeds aspecific threshold for each account. What should A solutions architect do to meet this requirement MOST cost-effectively?",
      "options": {
        "A": "Use Cost Explorer to create a daily report of costs by service. Filter the report by EC2 instances. Configure Cost Explorer to send an A mazon Simple Email Service (A mazon SES) notiFication when a threshold is exceeded.",
        "B": "Use Cost Explorer to create a monthly report of costs by service. Filter the report by EC2 instances. Configure Cost Explorer to send an A mazon Simple Email Service (A mazon SES) notiFication when a threshold is exceeded.",
        "C": "Use A WS Budgets to create a cost budget for each account. Set the period to monthly. Set the scope to EC2 instances. Set an alert threshold for the budget. Configure an A mazon Simple Notification Service (A mazon SNS) topic to receive a notiFication when a threshold is exceeded.",
        "D": "Use A WS Cost and Usage Reports to create a report with hourly granularity. Integrate the report data with A mazon A thena. Use A mazon EventBridge to schedule an A thena query. Configure an A mazon Simple Notification Service (A mazon SNS) topic to receive a notiFication when a threshold is exceeded."
      },
      "correct_answer": "C",
      "explanation": "A WS Budgets is a cost management service that allows you to set custom cost and usage budgets that alert you when you exceed your thresholds. In this case, you can create a monthly budget specifically for EC2 instances, and when the usage exceeds the defined threshold, it triggers an alert."
    },
    {
      "id": "239",
      "question": "A solutions architect needs to design a new microservice for A company\u2019s application. Clients must be able to call an HTTPS endpoint to reach the microservice. The microservice also must use A WS Identity and A ccess Management (IAM) to authenticate calls. The solutions architect will write the logic for this microservice by using a single A WS Lambda function that is written in Go 1.x. Which solution will deploy the function in the MOST operationally eficient way?",
      "options": {
        "A": "Create an A mazon A PI Gateway REST A PI. Configure the method to use the Lambda function. Enable IAM authentication on the A PI.",
        "B": "Create a Lambda function URL for the function. Specify A WS_IAM as the authentication type.",
        "C": "Create an A mazon CloudFront distribution. Deploy the function to Lambda@Edge. Integrate IAM authentication logic into the Lambda@Edge function.",
        "D": "Create an A mazon CloudFront distribution. Deploy the function to CloudFront Functions. Specify A WS_IAM as the authentication type."
      },
      "correct_answer": "A",
      "explanation": "This option is specifically designed for creating A PIs and provides features such as authentication, request validation, and more. It allows you to create a REST A PI, configure a method to invoke the Lambda function, and enable IAM authentication. This provides a dedicated and managed A PI endpoint for clients to call securely."
    },
    {
      "id": "240",
      "question": "A company previously migrated its data warehouse solution to A WS. The company also has an A WS Direct Connect connection. Corporate ofice users query the data warehouse using avisualization tool. The average size of aquery returned by the data warehouse is 50 MB and each webpage sent by the visualization tool is approximately 500 KB. Result sets returned by the data warehouse are not cached. Which solution provides the LOWEST data transfer egress cost for the company?",
      "options": {
        "A": "Host the visualization tool on premises and query the data warehouse directly over the internet.",
        "B": "Host the visualization tool in the same A WS Region as the data warehouse. A ccess it over the internet.",
        "C": "Host the visualization tool on premises and query the data warehouse directly over a Direct Connect connection at a location in the same A WS Region.",
        "D": "Host the visualization tool in the same A WS Region as the data warehouse and access it over a Direct Connect connection at a location in the same Region."
      },
      "correct_answer": "D",
      "explanation": "Hosting the visualization tool in the same A WS Region as the data warehouse and accessing it over a Direct Connect connection within the same Region minimizes data transfer costs. Since the data warehouse and the visualization tool are in the same Region, the data transfer between them doesn't incur the usual costs associated with data leaving the A WS network."
    },
    {
      "id": "241",
      "question": "A n online learning company is migrating to the A WS Cloud. The company maintains its student records in aPostgreSQL database. The company needs a solution in which its data is available and online across multiple A WS Regions at all times. Which solution will meet these requirements with the LEAST amount of operational overhead?",
      "options": {
        "A": "Migrate the PostgreSQL database to a PostgreSQL cluster on A mazon EC2 instances.",
        "B": "Migrate the PostgreSQL database to an A mazon RDS for PostgreSQL DB instance with the Multi-A Z feature turned on.",
        "C": "Migrate the PostgreSQL database to an A mazon RDS for PostgreSQL DB instance. Create a read replica in another Region.",
        "D": "Migrate the PostgreSQL database to an A mazon RDS for PostgreSQL DB instance. Set up DB snapshots to be copied to another Region."
      },
      "correct_answer": "C",
      "explanation": "A mazon RDS for PostgreSQL allows you to create read replicas in different A WS Regions. This provides cross-Region availability and redundancy. A dditionally, it allows you to offload read traffic from the primary database."
    },
    {
      "id": "242",
      "question": "A company hosts its web application on A WS using seven A mazon EC2 instances. The company requires that the IP addresses of all healthy EC2 instances be returned in response to DNS queries. Which policy should be used to meet this requirement?",
      "options": {
        "A": "Simple routing policy",
        "B": "Latency routing policy",
        "C": "Multivalue routing policy",
        "D": "Geolocation routing policy"
      },
      "correct_answer": "C",
      "explanation": "The multivalue routing policy returns multiple healthy IP addresses for the resource in response to DNS queries. This is suitable for distributing traffic across multiple resources, such as EC2 instances, and meeting the specified requirement.\nSimple Routing: Gives one answer (IP address).\nLatency Routing: Considers the fastest route but still gives one answer.\nMultivalue Routing: Gives multiple answers (multiple IP addresses).\nGeolocation Routing: Directs based on user location but typically gives one answer."
    },
    {
      "id": "243",
      "question": "A medical research lab produces data that is related to a new study. The lab wants to make the data available with minimum latency to clinics across the country for their on-premises, File-based applications. The data files are stored in an A mazon S3 bucket that has read-only permissions for each clinic. What should A solutions architect recommend to meet these requirements?",
      "options": {
        "A": "Deploy an A WS Storage Gateway File gateway as a virtual machine (VM) on premises at each clinic",
        "B": "Migrate the files to each clinic\u2019s on-premises applications by using A WS DataSync for processing.",
        "C": "Deploy an A WS Storage Gateway volume gateway as a virtual machine (VM) on premises at each clinic.",
        "D": "A ttach an A mazon Elastic File System (A mazon EFS) file system to each clinic\u2019s on-premises servers."
      },
      "correct_answer": "A",
      "explanation": "This option provides a way to present an S3 bucket as a file system to on-premises applications. Each clinic can deploy an A WS Storage Gateway file gateway as a VM on-premises, allowing them to access the data in the S3 bucket as if it were local files. It minimizes latency because the data is cached locally, and read-only permissions can be controlled at the S3 bucket level."
    },
    {
      "id": "244",
      "question": "A company is using acontent management system that runs on a single A mazon EC2 instance. The EC2 instance contains both the web server and the database software. The company must make its website platform highly available and must enable the website to scale to meet user demand. What should A solutions architect recommend to meet these requirements?",
      "options": {
        "A": "Move the database to A mazon RDS, and enable automatic backups. Manually launch another EC2 instance in the same A vailability Zone. Configure an A pplication Load Balancer in the A vailability Zone, and set the two instances as targets.",
        "B": "Migrate the database to an A mazon A urora instance with a read replica in the same A vailability Zone as the existing EC2 instance. Manually launch another EC2 instance in the same A vailability Zone. Configure an A pplication Load Balancer, and set the two EC2 instances as targets.",
        "C": "Move the database to A mazon A urora with a read replica in another A vailability Zone. Create an A mazon Machine Image (A MI) from the EC2 instance. Configure an A pplication Load Balancer in two A vailability Zones. A ttach an A uto Scaling group that uses the A MI across two A vailability Zones.",
        "D": "Move the database to a separate EC2 instance, and schedule backups to A mazon S3. Create an A mazon Machine Image (A MI) from the original EC2 instance. Configure an A pplication Load Balancer in two A vailability Zones. A ttach an A uto Scaling group that uses the A MI across two A vailability Zones."
      },
      "correct_answer": "C",
      "explanation": "This option provides both high availability and scalability. Using A mazon A urora with a read replica in another A vailability Zone ensures data redundancy and failover capabilities. Configuring an A pplication Load Balancer across two A vailability Zones and using A uto Scaling allows for scalability."
    },
    {
      "id": "245",
      "question": "A company is launching an application on A WS. The application uses an A pplication Load Balancer (A LB) to direct traffic to at least two A mazon EC2 instances in a single target group. The instances are in an A uto Scaling group for each environment. The company requires adevelopment environment and aproduction environment. The production environment will have periods of high traffic. Which solution will configure the development environment MOST cost-effectively?",
      "options": {
        "A": "ReconFigure the target group in the development environment to have only one EC2 instance as a target.",
        "B": "Change the A LB balancing algorithm to least outstanding requests.",
        "C": "Reduce the size of the EC2 instances in both environments.",
        "D": "Reduce the maximum number of EC2 instances in the development environment\u2019s A uto Scaling group."
      },
      "correct_answer": "A",
      "explanation": "For a development environment, where high availability and scalability might not be as critical as in production, having only one EC2 instance as a target in the target group could be a cost-effective solution. This reduces the number of running instances in the development environment when compared to production."
    },
    {
      "id": "246",
      "question": "A company runs a web application on A mazon EC2 instances in multiple A vailability Zones. The EC2 instances are in private subnets. A solutions architect implements an internet-facing A pplication Load Balancer (A LB) and specifies the EC2 instances as the target group. However, the internet traffic is not reaching the EC2 instances. How should the solutions architect reconfigure the architecture to resolve this issue?",
      "options": {
        "A": "Replace the A LB with a Network Load Balancer. Configure a NAT gateway in a public subnet to allow internet traffic.",
        "B": "Move the EC2 instances to public subnets. A dd a rule to the EC2 instances\u2019 security groups to allow outbound traffic to 0.0.0.0/0.",
        "C": "Update the route tables for the EC2 instances\u2019 subnets to send 0.0.0.0/0 traffic through the internet gateway route. A dd a rule to the EC2 instances\u2019 security groups to allow outbound traffic to 0.0.0.0/0.",
        "D": "Create public subnets in each A vailability Zone. A ssociate the public subnets with the A LB. Update the route tables for the public subnets with a route to the private subnets."
      },
      "correct_answer": "D",
      "explanation": "This option involves creating public subnets for the A LB, allowing it to receive internet traffic. The EC2 instances can remain in private subnets. This approach follows the best practice of using public subnets for internet-facing components like A LBs."
    },
    {
      "id": "247",
      "question": "A company has deployed a database in A mazon RDS for MySQL. Due to increased transactions, the database support team is reporting slow reads against the DB instance and recommends adding aread replica. Which combination of actions should A solutions architect take before implementing this change? (Choose two.)",
      "options": {
        "A": "Enable binlog replication on the RDS primary node.",
        "B": "Choose a failover priority for the source DB instance.",
        "C": "A llow long-running transactions to complete on the source DB instance.",
        "D": "Create a global table and specify the A WS Regions where the table will be available.",
        "E": "Enable automatic backups on the source instance by setting the backup retention period to a value other than 0."
      },
      "correct_answer": "CE",
      "explanation": ""
    },
    {
      "id": "248",
      "question": "A company runs analytics software on A mazon EC2 instances. The software accepts job requests from users to process data that has been uploaded to A mazon S3. Users report that some submitted data is not being processed A mazon Cloudwatch reveals that the EC2 instances have aconsistent CPU utilization at or near 100%. The company wants to improve system performance and scale the system based on user load. What should A solutions architect do to meet these requirements?",
      "options": {
        "A": "Create a copy of the instance. Place all instances behind an A pplication Load Balancer.",
        "B": "Create an S3 VPC endpoint for A mazon S3. Update the software to reference the endpoint.",
        "C": "Stop the EC2 instances. Modify the instance type to one with a more powerful CPU and more memory. Restart the instances.",
        "D": "Route incoming requests to A mazon Simple Queue Service (A mazon SQS). Configure an EC2 A uto Scaling group based on queue size. Update the software to read from the queue."
      },
      "correct_answer": "D",
      "explanation": "This option addresses the issue by offloading incoming requests to an SQS queue, allowing for decoupling of processing and scaling based on queue size. This helps improve system performance and allows for scaling based on user load."
    },
    {
      "id": "249",
      "question": "A company is implementing ashared storage solution for amedia application that is hosted in the A WS Cloud. The company needs the ability to use SMB clients to access data. The solution must be fully managed. Which A WS solution meets these requirements?",
      "options": {
        "A": "Create an A WS Storage Gateway volume gateway. Create a File share that uses the required client protocol. Connect the application server to the File share.",
        "B": "Create an A WS Storage Gateway tape gateway. Configure tapes to use A mazon S3. Connect the application server to the tape gateway.",
        "C": "Create an A mazon EC2 Windows instance. Install and conFigure a Windows File share role on the instance. Connect the application server to the File share.",
        "D": "Create an A mazon FSx for Windows File Server file system. A ttach the file system to the origin server. Connect the application server to the file system."
      },
      "correct_answer": "D",
      "explanation": "A mazon FSx for Windows File Server is a fully managed file storage service that supports the SMB protocol. It provides a native Windows file system experience and is designed to be accessed by SMB clients. This option meets the requirements for a fully managed shared storage solution accessible via SMB."
    },
    {
      "id": "250",
      "question": "A company\u2019s security team requests that network traffic be captured in VPC Flow Logs. The logs will be frequently accessed for 90 days and then accessed intermittently. What should A solutions architect do to meet these requirements when configuring the logs?",
      "options": {
        "A": "Use A mazon CloudWatch as the target. Set the CloudWatch log group with an expiration of 90 days",
        "B": "Use A mazon Kinesis as the target. Configure the Kinesis stream to always retain the logs for 90 days.",
        "C": "Use A WS CloudTrail as the target. Configure CloudTrail to save to an A mazon S3 bucket, and enable S3 Intelligent-Tiering.",
        "D": "Use A mazon S3 as the target. Enable an S3 Lifecycle policy to transition the logs to S3 Standard-Infrequent A ccess (S3 Standard-IA) after 90 days."
      },
      "correct_answer": "D",
      "explanation": "A mazon S3 is a scalable and cost-effective object storage service. Enabling an S3 Lifecycle policy to transition logs to S3 Standard-Infrequent A ccess (S3 Standard-IA) after 90 days is a suitable solution. This approach allows you to store the logs in a cost-effective manner, automatically moving them to a lower-cost storage class after the initial 90 days."
    }
  ]
}