{
  "questions": [
    {
      "id": "401",
      "question": "A company wants to use the A WS Cloud to make a n existing a pplication highly a vailable a nd resilient. The current version of the a pplication resides in the company's data center. The a pplication recently experienced data loss a fter a database server crashed because of a n unexpected power outage. The company needs a solution that a voids a ny single points of failure. The solution must give the a pplication the a bility to scale to meet user demand. Which solution will meet these requirements?",
      "options": {
        "A": "Deploy the a pplication servers by using A mazon EC2 instances in a n A uto Scaling group a cross multiple A vailability Zones. Use a n A mazon RDS DB instance in a Multi-A Z conFiguration.",
        "B": "Deploy the a pplication servers by using A mazon EC2 instances in a n A uto Scaling group in a single A vailability Zone. Deploy the database on a n EC2 instance. Enable EC2 A uto Recovery.",
        "C": "Deploy the a pplication servers by using A mazon EC2 instances in a n A uto Scaling group a cross multiple A vailability Zones. Use a n A mazon RDS DB instance with a read replica in a single A vailability Zone. Promote the read replica to replace the primary DB instance if the primary DB instance fails.",
        "D": "Deploy the a pplication servers by using A mazon EC2 instances in a n A uto Scaling group a cross multiple A vailability Zones. Deploy the primary a nd secondary database servers on EC2 instances a cross multiple A vailability Zones. Use A mazon Elastic Block Store (A mazon EBS) Multi-A ttach to create shared storage between the instances."
      },
      "correct_answer": "A",
      "explanation": "A uto Scaling A cross Multiple A vailability Zones: Deploying a pplication servers using EC2 instances in a n A uto Scaling group a cross multiple A vailability Zones (A Zs) helps a void a single point of failure. If one A Z experiences a n issue, the a pplication can continue to operate in a nother A Z."
    },
    {
      "id": "402",
      "question": "A company needs to ingest a nd handle large a mounts of streaming data that its a pplication generates. The a pplication runs on A mazon EC2 instances a nd sends data to A mazon Kinesis Data Streams, which is configured with default settings. Every other day, the a pplication consumes the data a nd writes the data to a n A mazon S3 bucket for business intelligence (BI) processing. The company observes that A mazon S3 is not receiving a ll the data that the a pplication sends to Kinesis Data Streams. What should A solutions a rchitect do to resolve this issue?",
      "options": {
        "A": "Update the Kinesis Data Streams default settings by modifying the data retention period.",
        "B": "Update the a pplication to use the Kinesis Producer Library (KPL) to send the data to Kinesis Data Streams.",
        "C": "Update the number of Kinesis shards to handle the throughput of the data that is sent to Kinesis Data Streams.",
        "D": "Turn on S3 Versioning within the S3 bucket to preserve every version of every object that is ingested in the S3 bucket."
      },
      "correct_answer": "A",
      "explanation": ""
    },
    {
      "id": "403",
      "question": "A developer has a n a pplication that uses a n A WS Lambda function to upload Files to A mazon S3 a nd needs the required permissions to perform the task. The developer a lready has a n IAM user with valid IAM credentials required for A mazon S3. What should A solutions a rchitect do to grant the permissions?",
      "options": {
        "A": "A dd required IAM permissions in the resource policy of the Lambda function.",
        "B": "Create a signed request using the existing IAM credentials in the Lambda function.",
        "C": "Create a new IAM user a nd use the existing IAM credentials in the Lambda function.",
        "D": "Create a n IAM execution role with the required permissions a nd a ttach the IAM role to the Lambda function."
      },
      "correct_answer": "D",
      "explanation": "o grant the necessary permissions to a n A WS Lambda function to upload files to A mazon S3, a solutions a rchitect should create a n IAM execution role with the required permissions a nd a ttach the IAM role to the Lambda function. This a pproach follows the principle of least privilege a nd ensures that the Lambda function can only a ccess the resources it needs to perform its specific task."
    },
    {
      "id": "404",
      "question": "A company has deployed a serverless a pplication that invokes a n A WS Lambda function when new documents a re uploaded to a n A mazon S3 bucket. The a pplication uses the Lambda function to process the documents. A fter a recent marketing campaign, the company noticed that the a pplication did not process many of the documents. What should A solutions a rchitect do to improve the a rchitecture of this a pplication?",
      "options": {
        "A": "Set the Lambda function's runtime timeout value to 15 minutes.",
        "B": "Configure a n S3 bucket replication policy. Stage the documents in the S3 bucket for later processing.",
        "C": "Deploy a n a dditional Lambda function. Load balance the processing of the documents a cross the two Lambda functions.",
        "D": "Create a n A mazon Simple Queue Service (A mazon SQS) queue. Send the requests to the queue. Configure the queue a s a n event source for Lambda."
      },
      "correct_answer": "D",
      "explanation": "Introducing A mazon SQS a s a queue a llows for better decoupling between the S3 events a nd the document processing. This ensures that the Lambda function is not overwhelmed with spikes in incoming events, leading to missed document processing."
    },
    {
      "id": "405",
      "question": "A solutions a rchitect is designing the a rchitecture for a software demonstration environment. The environment will run on A mazon EC2 instances in a n A uto Scaling group behind a n A pplication Load Balancer (A LB). The system will experience significant increases in traffic during working hours but is not required to operate on weekends. Which combination of a ctions should the solutions a rchitect take to ensure that the system can scale to meet demand? (Choose two.)",
      "options": {
        "A": "Use A WS A uto Scaling to a djust the A LB capacity based on request rate.",
        "B": "Use A WS A uto Scaling to scale the capacity of the VPC internet gateway.",
        "C": "Launch the EC2 instances in multiple A WS Regions to distribute the load a cross Regions.",
        "D": "Use a target tracking scaling policy to scale the A uto Scaling group based on instance CPU utilization.",
        "E": "Use scheduled scaling to change the A uto Scaling group minimum, maximum, a nd desired capacity to zero for weekends. Revert to the default values a t the start of the week."
      },
      "correct_answer": "DE",
      "explanation": "E. Use scheduled scaling to change the A uto Scaling group minimum, maximum, a nd desired capacity to zero for weekends. Revert to the default values a t the start of the week.\nThis a llows the A LB to a utomatically scale its capacity based on the incoming request rate, ensuring that the system can handle varying traffic loads.\nThis a llows you to save costs a nd resources during weekends when the system is not required to operate. Scaling down the A uto Scaling group to zero instances during weekends a nd reverting to the default values a t the start of the week ensures that you only incur costs when the system is a ctively in use."
    },
    {
      "id": "406",
      "question": "A solutions a rchitect is designing a two-tiered a rchitecture that includes a public subnet a nd a database subnet. The web servers in the public subnet must be open to the internet on port 443. The A mazon RDS for MySQL DB instance in the database subnet must be a ccessible only to the web servers on port 3306. Which combination of steps should the solutions a rchitect take to meet these requirements? (Choose two.)",
      "options": {
        "A": "Create a network A CL for the public subnet. A dd a rule to deny outbound traffic to 0.0.0.0/0 on port 3306.",
        "B": "Create a security group for the DB instance. A dd a rule to a llow traffic from the public subnet CIDR block on port 3306.",
        "C": "Create a security group for the web servers in the public subnet. A dd a rule to a llow traffic from 0.0.0.0/0 on port 443.",
        "D": "Create a security group for the DB instance. A dd a rule to a llow traffic from the web servers\u2019 security group on port 3306.",
        "E": "Create a security group for the DB instance. A dd a rule to deny a ll traffic except traffic from the web servers\u2019 security group on port 3306."
      },
      "correct_answer": "CD",
      "explanation": "D. Create a security group for the DB instance. A dd a rule to a llow traffic from the web servers\u2019 security group on port 3306.\nThis a llows inbound traffic from the internet on port 443 to the web servers.\nThis ensures that the RDS instance is a ccessible only from the web servers in the public subnet."
    },
    {
      "id": "407",
      "question": "A company is implementing a shared storage solution for a gaming a pplication that is hosted in the A WS Cloud. The company needs the a bility to use Lustre clients to a ccess data. The solution must be fully managed. Which solution meets these requirements?",
      "options": {
        "A": "Create a n A WS DataSync task that shares the data a s a mountable File system. Mount the File system to the a pplication server.",
        "B": "Create a n A WS Storage Gateway File gateway. Create a File share that uses the required client protocol. Connect the a pplication server to the File share.",
        "C": "Create a n A mazon Elastic File System (A mazon EFS) File system, a nd conFigure it to support Lustre. A ttach the File system to the origin server. Connect the a pplication server to the File system.",
        "D": "Create a n A mazon FSx for Lustre File system. A ttach the File system to the origin server. Connect the a pplication server to the File system."
      },
      "correct_answer": "D",
      "explanation": "A mazon FSx for Lustre: A mazon FSx for Lustre is a fully managed service that provides high-performance shared storage. It is specifically designed to be used with Lustre, making it a suitable solution for Lustre clients.\nFully Managed: A mazon FSx for Lustre is a fully managed service, meaning that A WS takes care of maintenance, updates, a nd other operational tasks, reducing the management overhead for the company."
    },
    {
      "id": "408",
      "question": "A company runs a n a pplication that receives data from thousands of geographically dispersed remote devices that use UDP. The a pplication processes the data immediately a nd sends a message back to the device if necessary. No data is stored. The company needs a solution that minimizes latency for the data transmission from the devices. The solution a lso must provide rapid failover to a nother A WS Region. Which solution will meet these requirements?",
      "options": {
        "A": "Configure a n A mazon Route 53 failover routing policy. Create a Network Load Balancer (NLB) in each of the two Regions. Configure the NLB to invoke a n A WS Lambda function to process the data.",
        "B": "Use A WS Global A ccelerator. Create a Network Load Balancer (NLB) in each of the two Regions a s a n endpoint. Create a n A mazon Elastic Container Service (A mazon ECS) cluster with the Fargate launch type. Create a n ECS service on the cluster. Set the ECS service a s the target for the NLProcess the data in A mazon ECS.",
        "C": "Use A WS Global A ccelerator. Create a n A pplication Load Balancer (A LB) in each of the two Regions a s a n endpoint. Create a n A mazon Elastic Container Service (A mazon ECS) cluster with the Fargate launch type. Create a n ECS service on the cluster. Set the ECS service a s the target for the A LB. Process the data in A mazon ECS.",
        "D": "Configure a n A mazon Route 53 failover routing policy. Create a n A pplication Load Balancer (A LB) in each of the two Regions. Create a n A mazon Elastic Container Service (A mazon ECS) cluster with the Fargate launch type. Create a n ECS service on the cluster. Set the ECS service a s the target for the A LB. Process the data in A mazon ECS."
      },
      "correct_answer": "B",
      "explanation": "A WS Global A ccelerator: A WS Global A ccelerator provides static IP a ddresses that a ct a s a fixed entry point to your a pplication. It routes traffic over the A WS global network to the optimal A WS endpoint based on health, geography, a nd routing policies.\nNetwork Load Balancer (NLB): NLB is well-suited for UDP-based traffic, a nd it's designed for high-performance, low-latency a pplications. In this case, it can efficiently handle the thousands of geographically dispersed remote devices sending UDP traffic.\nA mazon ECS with Fargate Launch Type: Using ECS with Fargate a llows you to deploy a nd run containers without managing the underlying infrastructure. This setup can efficiently handle the immediate processing of data without the need to manage the underlying servers."
    },
    {
      "id": "409",
      "question": "A solutions a rchitect must migrate a Windows Internet Information Services (IIS) web a pplication to A WS. The a pplication currently relies on a File share hosted in the user's on-premises network-a ttached storage (NAS). The solutions a rchitect has proposed migrating the IIS web servers to A mazon EC2 instances in multiple A vailability Zones that a re connected to the storage solution, a nd configuring a n Elastic Load Balancer a ttached to the instances. Which replacement to the on-premises File share is MOST resilient a nd durable?",
      "options": {
        "A": "Migrate the File share to A mazon RDS.",
        "B": "Migrate the File share to A WS Storage Gateway.",
        "C": "Migrate the File share to A mazon FSx for Windows File Server.",
        "D": "Migrate the File share to A mazon Elastic File System (A mazon EFS)."
      },
      "correct_answer": "C",
      "explanation": "A mazon FSx for Windows File Server: A mazon FSx is a fully managed file storage service that is compatible with Windows file systems. A mazon FSx for Windows File Server is specifically designed for Windows workloads, including IIS web a pplications. It provides a highly a vailable a nd durable file system that can be a ccessed by multiple EC2 instances in different A vailability Zones."
    },
    {
      "id": "410",
      "question": "A company is deploying a new a pplication on A mazon EC2 instances. The a pplication writes data to A mazon Elastic Block Store (A mazon EBS) volumes. The company needs to ensure that a ll data that is written to the EBS volumes is encrypted a t rest. Which solution will meet this requirement?",
      "options": {
        "A": "Create a n IAM role that speciFies EBS encryption. A ttach the role to the EC2 instances.",
        "B": "Create the EBS volumes a s encrypted volumes. A ttach the EBS volumes to the EC2 instances.",
        "C": "Create a n EC2 instance tag that has a key of Encrypt a nd a value of True. Tag a ll instances that require encryption a t the EBS level.",
        "D": "Create a n A WS Key Management Service (A WS KMS) key policy that enforces EBS encryption in the a ccount. Ensure that the key policy is a ctive."
      },
      "correct_answer": "B",
      "explanation": "By creating the EBS volumes a s encrypted volumes, you ensure that a ll data written to those volumes is a utomatically encrypted. This provides a straightforward a nd effective solution for meeting the encryption-a t-rest requirement."
    },
    {
      "id": "411",
      "question": "A company has a web a pplication with sporadic usage patterns. There is heavy usage a t the beginning of each month, moderate usage a t the start of each week, a nd unpredictable usage during the week. The a pplication consists of a web server a nd a MySQL database server running inside the data center. The company would like to move the a pplication to the A WS Cloud, a nd needs to select a cost-effective database platform that will not require database modifications. Which solution will meet these requirements?",
      "options": {
        "A": "A mazon DynamoDB",
        "B": "A mazon RDS for MySQL",
        "C": "MySQL-compatible A mazon A urora Serverless",
        "D": "MySQL deployed on A mazon EC2 in a n A uto Scaling group"
      },
      "correct_answer": "C",
      "explanation": "A urora Serverless is a serverless option for MySQL-compatible databases.\nIt a utomatically a djusts the database capacity based on a ctual usage, making it suitable for sporadic usage patterns.\nIt is MySQL-compatible, so it won't require significant database modifications."
    },
    {
      "id": "412",
      "question": "A n image-hosting company stores its objects in A mazon S3 buckets. The company wants to a void a ccidental exposure of the objects in the S3 buckets to the public. A ll S3 objects in the entire A WS a ccount need to remain private. Which solution will meet these requirements?",
      "options": {
        "A": "Use A mazon GuardDuty to monitor S3 bucket policies. Create a n a utomatic remediation a ction rule that uses a n A WS Lambda function to remediate a ny change that makes the objects public.",
        "B": "Use A WS Trusted A dvisor to Find publicly a ccessible S3 buckets. Configure email notiFications in Trusted A dvisor when a change is detected. Manually change the S3 bucket policy if it a llows public a ccess.",
        "C": "Use A WS Resource A ccess Manager to Find publicly a ccessible S3 buckets. Use A mazon Simple NotiFication Service (A mazon SNS) to invoke a n A WS Lambda function when a change is detected. Deploy a Lambda function that programmatically remediates the change.",
        "D": "Use the S3 Block Public A ccess feature on the a ccount level. Use A WS Organizations to create a service control policy (SCP) that prevents IAM users from changing the setting. A pply the SCP to the a ccount."
      },
      "correct_answer": "D",
      "explanation": "A WS Organizations a llows you to create service control policies (SCPs) that set fine-grained permissions for member a ccounts. In this case, you can create a n SCP that prevents IAM users from changing the S3 Block Public A ccess settings. A pplying this SCP to the a ccount ensures that the configured public a ccess settings remain in place a nd cannot be a ltered by IAM users."
    },
    {
      "id": "413",
      "question": "A n ecommerce company is experiencing a n increase in user traffic. The company\u2019s store is deployed on A mazon EC2 instances a s a two-tier web a pplication consisting of a web tier a nd a separate database tier. A s traffic increases, the company notices that the a rchitecture is causing significant delays in sending timely marketing a nd order confirmation email to users. The company wants to reduce the time it spends resolving complex email delivery issues a nd minimize operational overhead. What should A solutions a rchitect do to meet these requirements?",
      "options": {
        "A": "Create a separate a pplication tier using EC2 instances dedicated to email processing.",
        "B": "Configure the web instance to send email through A mazon Simple Email Service (A mazon SES).",
        "C": "Configure the web instance to send email through A mazon Simple NotiFication Service (A mazon SNS).",
        "D": "Create a separate a pplication tier using EC2 instances dedicated to email processing. Place the instances in a n A uto Scaling group."
      },
      "correct_answer": "B",
      "explanation": "A mazon Simple Email Service (A mazon SES) is a fully managed email sending service. By configuring the web instances to send emails through A mazon SES, the ecommerce company can offload the complexity of email delivery to a reliable a nd scalable service."
    },
    {
      "id": "414",
      "question": "A company has a business system that generates hundreds of reports each day. The business system saves the reports to a network share in CSV format. The company needs to store this data in the A WS Cloud in near-real time for a nalysis. Which solution will meet these requirements with the LEAST a dministrative overhead?",
      "options": {
        "A": "Use A WS DataSync to transfer the Files to A mazon S3. Create a scheduled task that runs a t the end of each day.",
        "B": "Create a n A mazon S3 File Gateway. Update the business system to use a new network share from the S3 File Gateway.",
        "C": "Use A WS DataSync to transfer the Files to A mazon S3. Create a n a pplication that uses the DataSync A PI in the a utomation workflow.",
        "D": "Deploy a n A WS Transfer for SFTP endpoint. Create a script that checks for new Files on the network share a nd uploads the new Files by using SFTP."
      },
      "correct_answer": "B",
      "explanation": ""
    },
    {
      "id": "415",
      "question": "A company is storing petabytes of data in A mazon S3 Standard. The data is stored in multiple S3 buckets a nd is a ccessed with varying frequency. The company does not know a ccess patterns for a ll the data. The company needs to implement a solution for each S3 bucket to optimize the cost of S3 usage. Which solution will meet these requirements with the MOST operational eficiency?",
      "options": {
        "A": "Create a n S3 Lifecycle conFiguration with a rule to transition the objects in the S3 bucket to S3 Intelligent-Tiering.",
        "B": "Use the S3 storage class a nalysis tool to determine the correct tier for each object in the S3 bucket. Move each object to the identiFied storage tier.",
        "C": "Create a n S3 Lifecycle conFiguration with a rule to transition the objects in the S3 bucket to S3 Glacier Instant Retrieval.",
        "D": "Create a n S3 Lifecycle conFiguration with a rule to transition the objects in the S3 bucket to S3 One Zone-Infrequent A ccess (S3 One Zone- IA)."
      },
      "correct_answer": "A",
      "explanation": "S3 Intelligent-Tiering: This storage class is designed to a utomatically a nd dynamically move objects between two a ccess tiers \u2013 frequent a nd infrequent a ccess \u2013 based on changing a ccess patterns. It is a good fit for data with unknown or changing a ccess patterns. It provides cost savings compared to S3 Standard while maintaining low-latency a ccess to frequently a ccessed objects."
    },
    {
      "id": "416",
      "question": "A rapidly growing global ecommerce company is hosting its web a pplication on A WS. The web a pplication includes static content a nd dynamic content. The website stores online transaction processing (OLTP) data in a n A mazon RDS database The website\u2019s users a re experiencing slow page loads. Which combination of a ctions should A solutions a rchitect take to resolve this issue? (Choose two.)",
      "options": {
        "A": "Configure a n A mazon Redshift cluster.",
        "B": "Set up a n A mazon CloudFront distribution.",
        "C": "Host the dynamic web content in A mazon S3.",
        "D": "Create a read replica for the RDS DB instance.",
        "E": "Configure a Multi-A Z deployment for the RDS DB instance."
      },
      "correct_answer": "BD",
      "explanation": "D. Create a read replica for the RDS DB instance.\nA mazon CloudFront is a content delivery network (CDN) that can improve the performance of a website by caching static content closer to the users. This reduces latency a nd improves page load times.\nConfigure CloudFront to distribute static content such a s images, stylesheets, a nd JavaScript files. This will offload the serving of static a ssets from the web servers, improving overall website performance.\nCreating a read replica for the A mazon RDS database a llows you to offload read traffic from the primary database, improving the overall database performance."
    },
    {
      "id": "417",
      "question": "A company uses A mazon EC2 instances a nd A WS Lambda functions to run its a pplication. The company has VPCs with public subnets a nd private subnets in its A WS a ccount. The EC2 instances run in a private subnet in one of the VPCs. The Lambda functions need direct network a ccess to the EC2 instances for the a pplication to work. The a pplication will run for a t least 1 year. The company expects the number of Lambda functions that the a pplication uses to increase during that time. The company wants to maximize its savings on a ll a pplication resources a nd to keep network latency between the services low. Which solution will meet these requirements?",
      "options": {
        "A": "Purchase a n EC2 Instance Savings Plan Optimize the Lambda functions\u2019 duration a nd memory usage a nd the number of invocations. Connect the Lambda functions to the private subnet that contains the EC2 instances.",
        "B": "Purchase a n EC2 Instance Savings Plan Optimize the Lambda functions' duration a nd memory usage, the number of invocations, a nd the a mount of data that is transferred. Connect the Lambda functions to a public subnet in the same VPC where the EC2 instances run.",
        "C": "Purchase a Compute Savings Plan. Optimize the Lambda functions\u2019 duration a nd memory usage, the number of invocations, a nd the a mount of data that is transferred. Connect the Lambda functions to the private subnet that contains the EC2 instances.",
        "D": "Purchase a Compute Savings Plan. Optimize the Lambda functions\u2019 duration a nd memory usage, the number of invocations, a nd the a mount of data that is transferred. Keep the Lambda functions in the Lambda service VPC."
      },
      "correct_answer": "C",
      "explanation": ""
    },
    {
      "id": "418",
      "question": "A solutions a rchitect needs to a llow team members to a ccess A mazon S3 buckets in two different A WS a ccounts: a development a ccount a nd a production a ccount. The team currently has a ccess to S3 buckets in the development a ccount by using unique IAM users that a re a ssigned to a n IAM group that has a ppropriate permissions in the a ccount. The solutions a rchitect has created a n IAM role in the production a ccount. The role has a policy that grants a ccess to a n S3 bucket in the production a ccount. Which solution will meet these requirements while complying with the principle of least privilege?",
      "options": {
        "A": "A ttach the A dministrator A ccess policy to the development a ccount users.",
        "B": "A dd the development a ccount a s a principal in the trust policy of the role in the production a ccount.",
        "C": "Turn off the S3 Block Public A ccess feature on the S3 bucket in the production a ccount.",
        "D": "Create a user in the production a ccount with unique credentials for each team member."
      },
      "correct_answer": "B",
      "explanation": "By a dding the development a ccount a s a principal in the trust policy of the IAM role in the production a ccount, you enable IAM users in the development a ccount to a ssume the role a nd gain temporary permissions to a ccess the S3 bucket in the production a ccount.\nThis a pproach follows the principle of least privilege because it a llows users in the development a ccount to a ccess only the specific resources (S3 bucket) defined in the trust policy of the IAM role."
    },
    {
      "id": "419",
      "question": "A company uses A WS Organizations with a ll features enabled a nd runs multiple A mazon EC2 workloads in the a p-southeast-2 Region. The company has a service control policy (SCP) that prevents a ny resources from being created in a ny other Region. A security policy requires the company to encrypt a ll data a t rest. A n a udit discovers that employees have created A mazon Elastic Block Store (A mazon EBS) volumes for EC2 instances without encrypting the volumes. The company wants a ny new EC2 instances that a ny IAM user or root user launches in a p-southeast-2 to use encrypted EBS volumes. The company wants a solution that will have minimal effect on employees who create EBS volumes. Which combination of steps will meet these requirements? (Choose two.)",
      "options": {
        "A": "In the A mazon EC2 console, select the EBS encryption a ccount a ttribute a nd deFine a default encryption key.",
        "B": "Create a n IAM permission boundary. A ttach the permission boundary to the root organizational unit (OU). DeFine the boundary to deny the ec2:CreateVolume a ction when the ec2:Encrypted condition equals false.",
        "C": "Create a n SCP. A ttach the SCP to the root organizational unit (OU). DeFine the SCP to deny the ec2:CreateVolume a ction whenthe ec2:Encrypted condition equals false.",
        "D": "Update the IAM policies for each a ccount to deny the ec2:CreateVolume a ction when the ec2:Encrypted condition equals false.",
        "E": "In the Organizations management a ccount, specify the Default EBS volume encryption setting."
      },
      "correct_answer": "CE",
      "explanation": "E. In the Organizations management a ccount, specify the Default EBS volume encryption setting."
    },
    {
      "id": "420",
      "question": "A company wants to use a n A mazon RDS for PostgreSQL DB cluster to simplify time-consuming database a dministrative tasks for production database workloads. The company wants to ensure that its database is highly a vailable a nd will provide a utomatic failover support in most scenarios in less than 40 seconds. The company wants to ofioad reads off of the primary instance a nd keep costs a s low a s possible. Which solution will meet these requirements?",
      "options": {
        "A": "Use a n A mazon RDS Multi-A Z DB instance deployment. Create one read replica a nd point the read workload to the read replica.",
        "B": "Use a n A mazon RDS Multi-A Z DB duster deployment Create two read replicas a nd point the read workload to the read replicas.",
        "C": "Use a n A mazon RDS Multi-A Z DB instance deployment. Point the read workload to the secondary instances in the Multi-A Z pair.",
        "D": "Use a n A mazon RDS Multi-A Z DB cluster deployment Point the read workload to the reader endpoint."
      },
      "correct_answer": "D",
      "explanation": "A mazon RDS Multi-A Z DB Cluster Deployment: This provides high a vailability by a utomatically replicating data to a standby instance in a different A vailability Zone. In case of a failure, A mazon RDS a utomatically fails over to the standby instance."
    },
    {
      "id": "421",
      "question": "A company runs a highly a vailable SFTP service. The SFTP service uses two A mazon EC2 Linux instances that run with elastic IP a ddresses to a ccept traffic from trusted IP sources on the internet. The SFTP service is backed by shared storage that is a ttached to the instances. User a ccounts a re created a nd managed a s Linux users in the SFTP servers. The company wants a serverless option that provides high IOPS performance a nd highly configurable security. The company a lso wants to maintain control over user permissions. Which solution will meet these requirements?",
      "options": {
        "A": "Create a n encrypted A mazon Elastic Block Store (A mazon EBS) volume. Create a n A WS Transfer Family SFTP service with a public endpoint that a llows only trusted IP a ddresses. A ttach the EBS volume to the SFTP service endpoint. Grant users a ccess to the SFTP service.",
        "B": "Create a n encrypted A mazon Elastic File System (A mazon EFS) volume. Create a n A WS Transfer Family SFTP service with elastic IP a ddresses a nd a VPC endpoint that has internet-facing a ccess. A ttach a security group to the endpoint that a llows only trusted IP a ddresses. A ttach the EFS volume to the SFTP service endpoint. Grant users a ccess to the SFTP service.",
        "C": "Create a n A mazon S3 bucket with default encryption enabled. Create a n A WS Transfer Family SFTP service with a public endpoint that a llows only trusted IP a ddresses. A ttach the S3 bucket to the SFTP service endpoint. Grant users a ccess to the SFTP service.",
        "D": "Create a n A mazon S3 bucket with default encryption enabled. Create a n A WS Transfer Family SFTP service with a VPC endpoint that has internal a ccess in a private subnet. A ttach a security group that a llows only trusted IP a ddresses. A ttach the S3 bucket to the SFTP service endpoint. Grant users a ccess to the SFTP service."
      },
      "correct_answer": "B",
      "explanation": ""
    },
    {
      "id": "422",
      "question": "A company is developing a new machine learning (ML) model solution on A WS. The models a re developed a s independent microservices that fetch a pproximately 1 GB of model data from A mazon S3 a t startup a nd load the data into memory. Users a ccess the models through a n a synchronous A PI. Users can send a request or a batch of requests a nd specify where the results should be sent. The company provides models to hundreds of users. The usage patterns for the models a re irregular. Some models could be unused for days or weeks. Other models could receive batches of thousands of requests a t a time. Which design should A solutions a rchitect recommend to meet these requirements?",
      "options": {
        "A": "Direct the requests from the A PI to a Network Load Balancer (NLB). Deploy the models a s A WS Lambda functions that a re invoked by the NLB.",
        "B": "Direct the requests from the A PI to a n A pplication Load Balancer (A LB). Deploy the models a s A mazon Elastic Container Service (A mazon ECS) services that read from a n A mazon Simple Queue Service (A mazon SQS) queue. Use A WS A pp Mesh to scale the instances of the ECS cluster based on the SQS queue size.",
        "C": "Direct the requests from the A PI into a n A mazon Simple Queue Service (A mazon SQS) queue. Deploy the models a s A WS Lambda functions that a re invoked by SQS events. Use A WS A uto Scaling to increase the number of vCPUs for the Lambda functions based on the SQS queue size.",
        "D": "Direct the requests from the A PI into a n A mazon Simple Queue Service (A mazon SQS) queue. Deploy the models a s A mazon Elastic Container Service (A mazon ECS) services that read from the queue. Enable A WS A uto Scaling on A mazon ECS for both the cluster a nd copies of the service based on the queue size."
      },
      "correct_answer": "D",
      "explanation": "A mazon ECS Services: Deploying the models a s A mazon ECS services a llows for flexibility in managing the containerized a pplications. ECS services can efficiently handle the startup process of fetching model data from A mazon S3 a nd loading it into memory.\nA pplication Load Balancer (A LB): The A LB is used to direct requests from the A PI to the ECS services. A LB provides a dvanced routing capabilities a nd can handle the a synchronous A PI requirements.\nA WS A pp Mesh: A WS A pp Mesh can be used to scale the instances of the ECS cluster based on the SQS queue size. This a llows for dynamic scaling based on demand, helping to efficiently use resources."
    },
    {
      "id": "423",
      "question": "A solutions a rchitect wants to use the following JSON text a s a n identity-based policy to grant specific permissions: Which IAM principals can the solutions a rchitect a ttach this policy to? (Choose two.)",
      "options": {
        "A": "Role",
        "B": "Group",
        "C": "Organization",
        "D": "A mazon Elastic Container Service (A mazon ECS) resource",
        "E": "A mazon EC2 resource"
      },
      "correct_answer": "AB",
      "explanation": ""
    },
    {
      "id": "424",
      "question": "A company is running a custom a pplication on A mazon EC2 On-Demand Instances. The a pplication has frontend nodes that need to run 24 hours a day, 7 days a week a nd backend nodes that need to run only for a short time based on workload. The number of backend nodes varies during the day. The company needs to scale out a nd scale in more instances based on workload. Which solution will meet these requirements MOST cost-effectively?",
      "options": {
        "A": "Use Reserved Instances for the frontend nodes. Use A WS Fargate for the backend nodes.",
        "B": "Use Reserved Instances for the frontend nodes. Use Spot Instances for the backend nodes.",
        "C": "Use Spot Instances for the frontend nodes. Use Reserved Instances for the backend nodes.",
        "D": "Use Spot Instances for the frontend nodes. Use A WS Fargate for the backend nodes."
      },
      "correct_answer": "B",
      "explanation": "Reserved Instances (RIs) for Frontend Nodes: Since the frontend nodes need to run 24/7, Reserved Instances provide a significant cost savings compared to On-Demand pricing. RIs a re a commitment to a consistent usage pattern, making them suitable for instances that need to run continuously.\nSpot Instances for Backend Nodes: Spot Instances a re a cost-effective option for workloads that can be interrupted or a re flexible regarding a vailability. A s the number of backend nodes varies during the day, using Spot Instances a llows you to take a dvantage of spare capacity a t a lower cost. Spot Instances a re suitable for short-lived, scalable, a nd flexible workloads."
    },
    {
      "id": "425",
      "question": "A company uses high block storage capacity to runs its workloads on premises. The company's daily peak input a nd output transactions per second a re not more than 15,000 IOPS. The company wants to migrate the workloads to A mazon EC2 a nd to provision disk performance independent of storage capacity. Which A mazon Elastic Block Store (A mazon EBS) volume type will meet these requirements MOST cost-effectively?",
      "options": {
        "A": "GP2 volume type",
        "B": "io2 volume type",
        "C": "GP3 volume type",
        "D": "io1 volume type"
      },
      "correct_answer": "C",
      "explanation": "General Purpose SSD (gp3) volumes a re designed to provide a balance of price a nd performance. They a llow you to provision IOPS independently of storage capacity, making them suitable for workloads with varying performance requirements. GP3 volumes offer a lower price per IOPS compared to io1 volumes a nd a re a good fit for general-purpose workloads."
    },
    {
      "id": "426",
      "question": "A company needs to store data from its healthcare a pplication. The a pplication\u2019s data frequently changes. A new regulation requires a udit a ccess a t a ll levels of the stored data. The company hosts the a pplication on a n on-premises infrastructure that is running out of storage capacity. A solutions a rchitect must securely migrate the existing data to A WS while satisfying the new regulation. Which solution will meet these requirements?",
      "options": {
        "A": "Use A WS DataSync to move the existing data to A mazon S3. Use A WS CloudTrail to log data events.",
        "B": "Use A WS Snowcone to move the existing data to A mazon S3. Use A WS CloudTrail to log management events.",
        "C": "Use A mazon S3 Transfer A cceleration to move the existing data to A mazon S3. Use A WS CloudTrail to log data events.",
        "D": "Use A WS Storage Gateway to move the existing data to A mazon S3. Use A WS CloudTrail to log management events."
      },
      "correct_answer": "D",
      "explanation": ""
    },
    {
      "id": "427",
      "question": "A solutions a rchitect is implementing a complex Java a pplication with a MySQL database. The Java a pplication must be deployed on A pache Tomcat a nd must be highly a vailable. What should the solutions a rchitect do to meet these requirements?",
      "options": {
        "A": "Deploy the a pplication in A WS Lambda. Configure a n A mazon A PI Gateway A PI to connect with the Lambda functions.",
        "B": "Deploy the a pplication by using A WS Elastic Beanstalk. Configure a load-balanced environment a nd a rolling deployment policy.",
        "C": "Migrate the database to A mazon ElastiCache. Configure the ElastiCache security group to a llow a ccess from the a pplication.",
        "D": "Launch a n A mazon EC2 instance. Install a MySQL server on the EC2 instance. Configure the a pplication on the server. Create a n A MI. Use the A MI to create a launch template with a n A uto Scaling group."
      },
      "correct_answer": "B",
      "explanation": "A WS Elastic Beanstalk: It is a fully managed service that simplifies the deployment a nd operation of a pplications, including web a pplications running A pache Tomcat. Elastic Beanstalk handles the deployment details, capacity provisioning, load balancing, a uto-scaling, a nd a pplication health monitoring, making it easier to deploy a nd manage your a pplications."
    },
    {
      "id": "428",
      "question": "A serverless a pplication uses A mazon A PI Gateway, A WS Lambda, a nd A mazon DynamoDB. The Lambda function needs permissions to read a nd write to the DynamoDB table. Which solution will give the Lambda function a ccess to the DynamoDB table MOST securely?",
      "options": {
        "A": "Create a n IAM user with programmatic a ccess to the Lambda function. A ttach a policy to the user that a llows read a nd write a ccess to the DynamoDB table. Store the a ccess_key_id a nd secret_access_key parameters a s part of the Lambda environment variables. Ensure that other A WS users do not have read a nd write a ccess to the Lambda function conFiguration.",
        "B": "Create a n IAM role that includes Lambda a s a trusted service. A ttach a policy to the role that a llows read a nd write a ccess to the DynamoDB table. Update the conFiguration of the Lambda function to use the new role a s the execution role.",
        "C": "Create a n IAM user with programmatic a ccess to the Lambda function. A ttach a policy to the user that a llows read a nd write a ccess to the DynamoDB table. Store the a ccess_key_id a nd secret_access_key parameters in A WS Systems Manager Parameter Store a s secure string parameters. Update the Lambda function code to retrieve the secure string parameters before connecting to the DynamoDB table.",
        "D": "Create a n IAM role that includes DynamoDB a s a trusted service. A ttach a policy to the role that a llows read a nd write a ccess from the Lambda function. Update the code of the Lambda function to a ttach to the new role a s a n execution role."
      },
      "correct_answer": "B",
      "explanation": "IAM Role with Lambda a s a Trusted Service: This a pproach follows the principle of least privilege. You create a n IAM role that specifically grants the required permissions to a ccess DynamoDB a nd makes Lambda a trusted service. This ensures that only Lambda functions a ssociated with this role can a ssume it."
    },
    {
      "id": "429",
      "question": "The following IAM policy is a ttached to a n IAM group. This is the only policy a pplied to the group. What a re the effective IAM permissions of this policy for group members?",
      "options": {
        "A": "Group members a re permitted a ny A mazon EC2 a ction within the us-east-1 Region. Statements a fter the A llow permission a re not a pplied.",
        "B": "Group members a re denied a ny A mazon EC2 permissions in the us-east-1 Region unless they a re logged in with multi-factor a uthentication (MFA).",
        "C": "Group members a re a llowed the ec2:StopInstances a nd ec2:TerminateInstances permissions for a ll Regions when logged in with multi- factor a uthentication (MFA). Group members a re permitted a ny other A mazon EC2 a ction.",
        "D": "Group members a re a llowed the ec2:StopInstances a nd ec2:TerminateInstances permissions for the us-east-1 Region only when logged in with multi-factor a uthentication (MFA). Group members a re permitted a ny other A mazon EC2 a ction within the us-east-1 Region."
      },
      "correct_answer": "D",
      "explanation": ""
    },
    {
      "id": "430",
      "question": "A manufacturing company has machine sensors that upload .csv Files to a n A mazon S3 bucket. These .csv Files must be converted into images a nd must be made a vailable a s soon a s possible for the a utomatic generation of graphical reports. The images become irrelevant a fter 1 month, but the .csv Files must be kept to train machine learning (ML) models twice a year. The ML trainings a nd a udits a re planned weeks in a dvance. Which combination of steps will meet these requirements MOST cost-effectively? (Choose two.)",
      "options": {
        "A": "Launch a n A mazon EC2 Spot Instance that downloads the .csv Files every hour, generates the image Files, a nd uploads the images to the S3 bucket.",
        "B": "Design a n A WS Lambda function that converts the .csv Files into images a nd stores the images in the S3 bucket. Invoke the Lambda function when a .csv File is uploaded.",
        "C": "Create S3 Lifecycle rules for .csv Files a nd image Files in the S3 bucket. Transition the .csv Files from S3 Standard to S3 Glacier 1 day a fter they a re uploaded. Expire the image Files a fter 30 days.",
        "D": "Create S3 Lifecycle rules for .csv Files a nd image Files in the S3 bucket. Transition the .csv Files from S3 Standard to S3 One Zone-Infrequent A ccess (S3 One Zone-IA) 1 day a fter they a re uploaded. Expire the image Files a fter 30 days.",
        "E": "Create S3 Lifecycle rules for .csv Files a nd image Files in the S3 bucket. Transition the .csv Files from S3 Standard to S3 Standard-Infrequent A ccess (S3 Standard-IA) 1 day a fter they a re uploaded. Keep the image Files in Reduced Redundancy Storage (RRS)."
      },
      "correct_answer": "BC",
      "explanation": "C. Create S3 Lifecycle rules for .csv files a nd image files in the S3 bucket. Transition the .csv files from S3 Standard to S3 Glacier 1 day a fter they a re uploaded. Expire the image files a fter 30 days."
    },
    {
      "id": "431",
      "question": "A company has developed a new video game a s a web a pplication. The a pplication is in a three-tier a rchitecture in a VPC with A mazon RDS for MySQL in the database layer. Several players will compete concurrently online. The game\u2019s developers want to display a top-10 scoreboard in near- real time a nd offer the a bility to stop a nd restore the game while preserving the current scores. What should A solutions a rchitect do to meet these requirements?",
      "options": {
        "A": "Set up a n A mazon ElastiCache for Memcached cluster to cache the scores for the web a pplication to display.",
        "B": "Set up a n A mazon ElastiCache for Redis cluster to compute a nd cache the scores for the web a pplication to display.",
        "C": "Place a n A mazon CloudFront distribution in front of the web a pplication to cache the scoreboard in a section of the a pplication.",
        "D": "Create a read replica on A mazon RDS for MySQL to run queries to compute the scoreboard a nd serve the read traffic to the web a pplication."
      },
      "correct_answer": "B",
      "explanation": "Redis is a n in-memory data store that is well-suited for caching a nd real-time data processing. By setting up a n ElastiCache for Redis cluster, you can compute a nd cache the scores in-memory, a llowing for fast retrieval a nd updates."
    },
    {
      "id": "432",
      "question": "A n ecommerce company wants to use machine learning (ML) a lgorithms to build a nd train models. The company will use the models to visualize complex scenarios a nd to detect trends in customer data. The a rchitecture team wants to integrate its ML models with a reporting platform to a nalyze the a ugmented data a nd use the data directly in its business intelligence dashboards. Which solution will meet these requirements with the LEAST operational overhead?",
      "options": {
        "A": "Use A WS Glue to create a n ML transform to build a nd train models. Use A mazon OpenSearch Service to visualize the data.",
        "B": "Use A mazon SageMaker to build a nd train models. Use A mazon QuickSight to visualize the data.",
        "C": "Use a pre-built ML A mazon Machine Image (A MI) from the A WS Marketplace to build a nd train models. Use A mazon OpenSearch Service to visualize the data.",
        "D": "Use A mazon QuickSight to build a nd train models by using calculated Fields. Use A mazon QuickSight to visualize the data."
      },
      "correct_answer": "B",
      "explanation": "A mazon SageMaker: It is a fully managed service for building, training, a nd deploying machine learning models. SageMaker simplifies the ML workflow a nd reduces operational overhead. It provides a fully managed Jupyter Notebook instance for model development a nd training, a nd it can seamlessly integrate with other A WS services.\nQuickSight can directly connect to A mazon SageMaker models a nd use the results for visualization without the need for extensive data movement or transformation."
    },
    {
      "id": "433",
      "question": "A company is running its production a nd nonproduction environment workloads in multiple A WS a ccounts. The a ccounts a re in a n organization in A WS Organizations. The company needs to design a solution that will prevent the modification of cost usage tags. Which solution will meet these requirements?",
      "options": {
        "A": "Create a custom A WS ConFig rule to prevent tag modiFication except by a uthorized principals.",
        "B": "Create a custom trail in A WS CloudTrail to prevent tag modiFication.",
        "C": "Create a service control policy (SCP) to prevent tag modiFication except by a uthorized principals.",
        "D": "Create custom A mazon CloudWatch logs to prevent tag modiFication."
      },
      "correct_answer": "C",
      "explanation": "SCPs in A WS Organizations a re used to set fine-grained permissions on what a ctions A WS a ccounts within the organization can perform. You can create a custom SCP to specifically control a ccess to tag modification."
    },
    {
      "id": "434",
      "question": "A company hosts its a pplication in the A WS Cloud. The a pplication runs on A mazon EC2 instances behind a n Elastic Load Balancer in a n A uto Scaling group a nd with a n A mazon DynamoDB table. The company wants to ensure the a pplication can be made a vailable in a notherAWS Region with minimal downtime. What should A solutions a rchitect do to meet these requirements with the LEAST a mount of downtime?",
      "options": {
        "A": "Create a n A uto Scaling group a nd a load balancer in the disaster recovery Region. Configure the DynamoDB table a s a global table. Configure DNS failover to point to the new disaster recovery Region's load balancer.",
        "B": "Create a n A WS CloudFormation template to create EC2 instances, load balancers, a nd DynamoDB tables to be launched when needed Configure DNS failover to point to the new disaster recovery Region's load balancer.",
        "C": "Create a n A WS CloudFormation template to create EC2 instances a nd a load balancer to be launched when needed. Configure the DynamoDB table a s a global table. Configure DNS failover to point to the new disaster recovery Region's load balancer.",
        "D": "Create a n A uto Scaling group a nd load balancer in the disaster recovery Region. Configure the DynamoDB table a s a global table. Create a n A mazon CloudWatch a larm to trigger a n A WS Lambda function that updates A mazon Route 53 pointing to the disaster recovery load balancer."
      },
      "correct_answer": "A",
      "explanation": ""
    },
    {
      "id": "435",
      "question": "A company needs to migrate a MySQL database from its on-premises data center to A WS within 2 weeks. The database is 20 TB in size. The company wants to complete the migration with minimal downtime. Which solution will migrate the database MOST cost-effectively?",
      "options": {
        "A": "Order a n A WS Snowball Edge Storage Optimized device. Use A WS Database Migration Service (A WS DMS) with A WS Schema Conversion Tool (A WS SCT) to migrate the database with replication of ongoing changes. Send the Snowball Edge device to A WS to Finish the migration a nd continue the ongoing replication.",
        "B": "Order a n A WS Snowmobile vehicle. Use A WS Database Migration Service (A WS DMS) with A WS Schema Conversion Tool (A WS SCT) to migrate the database with ongoing changes. Send the Snowmobile vehicle back to A WS to Finish the migration a nd continue the ongoing replication.",
        "C": "Order a n A WS Snowball Edge Compute Optimized with GPU device. Use A WS Database Migration Service (A WS DMS) with A WS Schema Conversion Tool (A WS SCT) to migrate the database with ongoing changes. Send the Snowball device to A WS to Finish the migration a nd continue the ongoing replication",
        "D": "Order a 1 GB dedicated A WS Direct Connect connection to establish a connection with the data center. Use A WS Database Migration Service (A WS DMS) with A WS Schema Conversion Tool (A WS SCT) to migrate the database with replication of ongoing changes."
      },
      "correct_answer": "A",
      "explanation": "This is a cost-effective solution for shipping large a mounts of data to A WS. Snowball Edge devices a re designed for efficient data transfer, a nd they can handle the 20 TB database.\nA WS DMS is a managed service for migrating databases to A WS, a nd A WS SCT can a ssist in converting the database schema. Using these tools in combination a llows for a smooth migration process."
    },
    {
      "id": "436",
      "question": "A company moved its on-premises PostgreSQL database to a n A mazon RDS for PostgreSQL DB instance. The company successfully launched a new product. The workload on the database has increased. The company wants to a ccommodate the larger workload without a dding infrastructure. Which solution will meet these requirements MOST cost-effectively?",
      "options": {
        "A": "Buy reserved DB instances for the total workload. Make the A mazon RDS for PostgreSQL DB instance larger.",
        "B": "Make the A mazon RDS for PostgreSQL DB instance a Multi-A Z DB instance.",
        "C": "Buy reserved DB instances for the total workload. A dd a nother A mazon RDS for PostgreSQL DB instance.",
        "D": "Make the A mazon RDS for PostgreSQL DB instance a n on-demand DB instance."
      },
      "correct_answer": "A",
      "explanation": "When you commit to using a database instance for a longer time (with reserved instances), A WS gives you a discount compared to paying on a month-to-month basis.\nImagine you have a computer, a nd you want to make it more powerful because you have more things to do on it. Making the instance larger means upgrading the power of your virtual computer."
    },
    {
      "id": "437",
      "question": "A company operates a n ecommerce website on A mazon EC2 instances behind a n A pplication Load Balancer (A LB) in a n A uto Scaling group. The site is experiencing performance issues related to a high request rate from illegitimate external systems with changing IP a ddresses. The security team is worried a bout potential DDoS a ttacks a gainst the website. The company must block the illegitimate incoming requests in a way that has a minimal impact on legitimate users. What should A solutions a rchitect recommend?",
      "options": {
        "A": "Deploy A mazon Inspector a nd a ssociate it with the A LB.",
        "B": "Deploy A WS WAF, a ssociate it with the A LB, a nd conFigure a rate-limiting rule.",
        "C": "Deploy rules to the network A CLs a ssociated with the A LB to block the incoming traffic.",
        "D": "Deploy A mazon GuardDuty a nd enable rate-limiting protection when conFiguring GuardDuty."
      },
      "correct_answer": "B",
      "explanation": "A WS WAF is a web a pplication firewall service that helps protect your web a pplications from common web exploits. It a llows you to create rules to filter a nd monitor HTTP a nd HTTPS traffic based on conditions that you define.\nBy a ssociating A WS WAF with the A LB, you can inspect a nd filter incoming traffic before it reaches your instances, providing a layer of protection a gainst DDoS a ttacks a nd other malicious a ctivities."
    },
    {
      "id": "438",
      "question": "A company wants to share a ccounting data with a n external a uditor. The data is stored in a n A mazon RDS DB instance that resides in a private subnet. The a uditor has its own A WS a ccount a nd requires its own copy of the database. What is the MOST secure way for the company to share the database with the a uditor?",
      "options": {
        "A": "Create a read replica of the database. Configure IAM standard database a uthentication to grant the a uditor a ccess.",
        "B": "Export the database contents to text Files. Store the Files in a n A mazon S3 bucket. Create a new IAM user for the a uditor. Grant the user a ccess to the S3 bucket.",
        "C": "Copy a snapshot of the database to a n A mazon S3 bucket. Create a n IAM user. Share the user's keys with the a uditor to grant a ccess to the object in the S3 bucket.",
        "D": "Create a n encrypted snapshot of the database. Share the snapshot with the a uditor. A llow a ccess to the A WS Key Management Service (A WS KMS) encryption key."
      },
      "correct_answer": "D",
      "explanation": "Creating a n encrypted snapshot ensures that the database data is protected during the transfer a nd storage process.\nSharing the encrypted snapshot with the a uditor a llows them to create their own copy of the database securely.\nBy a llowing a ccess to the A WS KMS encryption key, the a uditor can decrypt the snapshot a nd restore it to their own environment."
    },
    {
      "id": "439",
      "question": "A solutions a rchitect configured a VPC that has a small range of IP a ddresses. The number of A mazon EC2 instances that a re in the VPC is increasing, a nd there is a n insuficient number of IP a ddresses for future workloads. Which solution resolves this issue with the LEAST operational overhead?",
      "options": {
        "A": "A dd a n a dditional IPv4 CIDR block to increase the number of IP a ddresses a nd create a dditional subnets in the VPC. Create new resources in the new subnets by using the new CIDR.",
        "B": "Create a second VPC with a dditional subnets. Use a peering connection to connect the second VPC with the First VPC Update the routes a nd create new resources in the subnets of the second VPC.",
        "C": "Use A WS Transit Gateway to a dd a transit gateway a nd connect a second VPC with the First VPUpdate the routes of the transit gateway a nd VPCs. Create new resources in the subnets of the second VPC.",
        "D": "Create a second VPC. Create a Site-to-Site VPN connection between the First VPC a nd the second VPC by using a VPN-hosted solution on A mazon EC2 a nd a virtual private gateway. Update the route between VPCs to the traffic through the VPN. Create new resources in the subnets of the second VPC."
      },
      "correct_answer": "A",
      "explanation": "By a dding a n a dditional IPv4 CIDR block to the existing VPC, you can effectively increase the number of a vailable IP a ddresses within the same VPC.\nCreating a dditional subnets using the new CIDR block a llows you to organize your resources a nd maintain segmentation within the VPC."
    },
    {
      "id": "440",
      "question": "A company used a n A mazon RDS for MySQL DB instance during a pplication testing. Before terminating the DB instance a t the end of the test cycle, A solutions a rchitect created two backups. The solutions a rchitect created the First backup by using the mysqldump utility to create a database dump. The solutions a rchitect created the second backup by enabling the Final DB snapshot option on RDS termination. The company is now planning for a new test cycle a nd wants to create a new DB instance from the most recent backup. The company has chosen a MySQL-compatible edition ofamazon A urora to host the DB instance. Which solutions will create the new DB instance? (Choose two.)",
      "options": {
        "A": "Import the RDS snapshot directly into A urora.",
        "B": "Upload the RDS snapshot to A mazon S3. Then import the RDS snapshot into A urora.",
        "C": "Upload the database dump to A mazon S3. Then import the database dump into A urora.",
        "D": "Use A WS Database Migration Service (A WS DMS) to import the RDS snapshot into A urora.",
        "E": "Upload the database dump to A mazon S3. Then use A WS Database Migration Service (A WS DMS) to import the database dump into A urora."
      },
      "correct_answer": "AC",
      "explanation": "C. Upload the database dump to A mazon S3. Then import the database dump into A urora.\nA. A mazon A urora a llows you to directly import a n A mazon RDS snapshot into A urora. This is a straightforward process for migrating data from RDS to A urora.\nC. Uploading the database dump to A mazon S3 a nd then importing the database dump into A urora is a common method. You can use the MySQL-compatible version of A urora to restore the data from a database dump stored in A mazon S3."
    },
    {
      "id": "441",
      "question": "A company hosts a multi-tier web a pplication on A mazon Linux A mazon EC2 instances behind a n A pplication Load Balancer. The instances run in a n A uto Scaling group a cross multiple A vailability Zones. The company observes that the A uto Scaling group launches more On-Demand Instances when the a pplication's end users a ccess high volumes of static web content. The company wants to optimize cost. What should A solutions a rchitect do to redesign the a pplication MOST cost-effectively?",
      "options": {
        "A": "Update the A uto Scaling group to use Reserved Instances instead of On-Demand Instances.",
        "B": "Update the A uto Scaling group to scale by launching Spot Instances instead of On-Demand Instances.",
        "C": "Create a n A mazon CloudFront distribution to host the static web contents from a n A mazon S3 bucket.",
        "D": "Create a n A WS Lambda function behind a n A mazon A PI Gateway A PI to host the static website contents."
      },
      "correct_answer": "C",
      "explanation": "A mazon CloudFront is a content delivery network (CDN) service that delivers static a nd dynamic web content, including images, videos, CSS, a nd JavaScript, with low latency a nd high transfer speeds. It can be used to cache a nd distribute static content globally, reducing the load on your web servers.\nBy creating a CloudFront distribution a nd hosting static web content in a n A mazon S3 bucket, you offload the serving of static content to the CDN, which can significantly reduce the load on your EC2 instances."
    },
    {
      "id": "442",
      "question": "A company stores several petabytes of data a cross multiple A WS a ccounts. The company uses A WS Lake Formation to manage its data lake. The company's data science team wants to securely share selective data from its a ccounts with the company's engineering team for a nalytical purposes. Which solution will meet these requirements with the LEAST operational overhead?",
      "options": {
        "A": "Copy the required data to a common a ccount. Create a n IAM a ccess role in that a ccount. Grant a ccess by specifying a permission policy that includes users from the engineering team a ccounts a s trusted entities.",
        "B": "Use the Lake Formation permissions Grant command in each a ccount where the data is stored to a llow the required engineering team users to a ccess the data.",
        "C": "Use A WS Data Exchange to privately publish the required data to the required engineering team a ccounts.",
        "D": "Use Lake Formation tag-based a ccess control to a uthorize a nd grant cross-a ccount permissions for the required data to the engineering team a ccounts."
      },
      "correct_answer": "D",
      "explanation": "Lake Formation a llows you to use tag-based a ccess control to a uthorize a nd grant permissions for data in the data lake. You can a pply tags to databases a nd tables, a nd then use those tags to control a ccess to the data.\nBy a pplying tags to the relevant data a nd using tag-based a ccess control, you can easily manage a ccess to specific data sets without having to create a dditional IAM roles or copy data to a common a ccount."
    },
    {
      "id": "443",
      "question": "A company wants to host a scalable web a pplication on A WS. The a pplication will be a ccessed by users from different geographic regions of the world. A pplication users will be a ble to download a nd upload unique data up to gigabytes in size. The development team wants a cost-effective solution to minimize upload a nd download latency a nd maximize performance. What should A solutions a rchitect do to a ccomplish this?",
      "options": {
        "A": "Use A mazon S3 with Transfer A cceleration to host the a pplication.",
        "B": "Use A mazon S3 with CacheControl headers to host the a pplication.",
        "C": "Use A mazon EC2 with A uto Scaling a nd A mazon CloudFront to host the a pplication.",
        "D": "Use A mazon EC2 with A uto Scaling a nd A mazon ElastiCache to host the a pplication."
      },
      "correct_answer": "A",
      "explanation": ""
    },
    {
      "id": "444",
      "question": "A company has hired A solutions a rchitect to design a reliable a rchitecture for its a pplication. The a pplication consists of one A mazon RDS DB instance a nd two manually provisioned A mazon EC2 instances that run web servers. The EC2 instances a re located in a single A vailability Zone. A n employee recently deleted the DB instance, a nd the a pplication was unavailable for 24 hours a s a result. The company is concerned with the overall reliability of its environment. What should the solutions a rchitect do to maximize reliability of the a pplication's infrastructure?",
      "options": {
        "A": "Delete one EC2 instance a nd enable termination protection on the other EC2 instance. Update the DB instance to be Multi-A Z, a nd enable deletion protection.",
        "B": "Update the DB instance to be Multi-A Z, a nd enable deletion protection. Place the EC2 instances behind a n A pplication Load Balancer, a nd run them in a n EC2 A uto Scaling group a cross multiple A vailability Zones.",
        "C": "Create a n a dditional DB instance a long with a n A mazon A PI Gateway a nd a n A WS Lambda function. Configure the a pplication to invoke the Lambda function through A PI Gateway. Have the Lambda function write the data to the two DB instances.",
        "D": "Place the EC2 instances in a n EC2 A uto Scaling group that has multiple subnets located in multiple A vailability Zones. Use Spot Instances instead of On-Demand Instances. Set up A mazon CloudWatch a larms to monitor the health of the instances Update the DB instance to be Multi-A Z, a nd enable deletion protection."
      },
      "correct_answer": "B",
      "explanation": "Multi-A Z RDS Instance: By updating the DB instance to be Multi-A Z, you ensure that there is a standby replica in a different A vailability Zone, providing high a vailability a nd a utomatic failover in case of a failure in the primary zone.\nDeletion Protection: Enabling deletion protection for the DB instance helps prevent a ccidental deletion, reducing the risk of downtime caused by human error."
    },
    {
      "id": "445",
      "question": "A company is storing 700 terabytes of data on a large network-a ttached storage (NAS) system in its corporate data center. The company has a hybrid environment with a 10 Gbps A WS Direct Connect connection. A fter a n a udit from a regulator, the company has 90 days to move the data to the cloud. The company needs to move the data eficiently a nd without disruption. The company still needs to be a ble to a ccess a nd update the data during the transfer window. Which solution will meet these requirements?",
      "options": {
        "A": "Create a n A WS DataSync a gent in the corporate data center. Create a data transfer task Start the transfer to a n A mazon S3 bucket.",
        "B": "Back up the data to A WS Snowball Edge Storage Optimized devices. Ship the devices to a n A WS data center. Mount a target A mazon S3 bucket on the on-premises File system.",
        "C": "Use rsync to copy the data directly from local storage to a designated A mazon S3 bucket over the Direct Connect connection.",
        "D": "Back up the data on tapes. Ship the tapes to a n A WS data center. Mount a target A mazon S3 bucket on the on-premises File system."
      },
      "correct_answer": "A",
      "explanation": "using A WS DataSync, which is designed for efficiently transferring large a mounts of data between on-premises storage a nd A mazon S3. It a llows you to create data transfer tasks a nd initiate the transfer to a n A mazon S3 bucket."
    },
    {
      "id": "446",
      "question": "A company stores data in PDF format in a n A mazon S3 bucket. The company must follow a legal requirement to retain a ll new a nd existing data in A mazon S3 for 7 years. Which solution will meet these requirements with the LEAST operational overhead?",
      "options": {
        "A": "Turn on the S3 Versioning feature for the S3 bucket. Configure S3 Lifecycle to delete the data a fter 7 years. Configure multi-factor a uthentication (MFA) delete for a ll S3 objects.",
        "B": "Turn on S3 Object Lock with governance retention mode for the S3 bucket. Set the retention period to expire a fter 7 years. Recopy a ll existing objects to bring the existing data into compliance.",
        "C": "Turn on S3 Object Lock with compliance retention mode for the S3 bucket. Set the retention period to expire a fter 7 years. Recopy a ll existing objects to bring the existing data into compliance.",
        "D": "Turn on S3 Object Lock with compliance retention mode for the S3 bucket. Set the retention period to expire a fter 7 years. Use S3 Batch Operations to bring the existing data into compliance."
      },
      "correct_answer": "D",
      "explanation": ""
    },
    {
      "id": "447",
      "question": "A company has a stateless web a pplication that runs on A WS Lambda functions that a re invoked by A mazon A PI Gateway. The company wants to deploy the a pplication a cross multiple A WS Regions to provide Regional failover capabilities. What should A solutions a rchitect do to route traffic to multiple Regions?",
      "options": {
        "A": "Create A mazon Route 53 health checks for each Region. Use a n a ctive-a ctive failover conFiguration.",
        "B": "Create a n A mazon CloudFront distribution with a n origin for each Region. Use CloudFront health checks to route traffic.",
        "C": "Create a transit gateway. A ttach the transit gateway to the A PI Gateway endpoint in each Region. Configure the transit gateway to route requests.",
        "D": "Create a n A pplication Load Balancer in the primary Region. Set the target group to point to the A PI Gateway endpoint hostnames in each Region."
      },
      "correct_answer": "A",
      "explanation": "By creating A mazon Route 53 health checks for each Region a nd configuring a n a ctive-a ctive failover configuration, Route 53 can monitor the health of the endpoints in each Region a nd route traffic to healthy endpoints. In the event of a failure in one Region, Route 53 a utomatically routes traffic to the healthy endpoints in other Regions."
    },
    {
      "id": "448",
      "question": "A company has two VPCs named Management a nd Production. The Management VPC uses VPNs through a customer gateway to connect to a single device in the data center. The Production VPC uses a virtual private gateway with two a ttached A WS Direct Connect connections. The Management a nd Production VPCs both use a single VPC peering connection to a llow communication between the a pplications. What should A solutions a rchitect do to mitigate a ny single point of failure in this a rchitecture?",
      "options": {
        "A": "A dd a set of VPNs between the Management a nd Production VPCs.",
        "B": "A dd a second virtual private gateway a nd a ttach it to the Management VPC.",
        "C": "A dd a second set of VPNs to the Management VPC from a second customer gateway device.",
        "D": "A dd a second VPC peering connection between the Management VPC a nd the Production VPC."
      },
      "correct_answer": "C",
      "explanation": "A dding a second set of VPN connections from the Management VPC to a second customer gateway device provides redundancy a nd eliminates this single point of failure."
    },
    {
      "id": "449",
      "question": "A company runs its a pplication on a n Oracle database. The company plans to quickly migrate to A WS because of limited resources for the database, backup a dministration, a nd data center maintenance. The a pplication uses third-party database features that require privileged a ccess. Which solution will help the company migrate the database to A WS MOST cost-effectively?",
      "options": {
        "A": "Migrate the database to A mazon RDS for Oracle. Replace third-party features with cloud services.",
        "B": "Migrate the database to A mazon RDS Custom for Oracle. Customize the database settings to support third-party features.",
        "C": "Migrate the database to a n A mazon EC2 A mazon Machine Image (A MI) for Oracle. Customize the database settings to support third-party features.",
        "D": "Migrate the database to A mazon RDS for PostgreSQL by rewriting the a pplication code to remove dependency on Oracle A PEX."
      },
      "correct_answer": "B",
      "explanation": ""
    },
    {
      "id": "450",
      "question": "A company has a three-tier web a pplication that is in a single server. The company wants to migrate the a pplication to the A WS Cloud. The company a lso wants the a pplication to a lign with the A WS Well-A rchitected Framework a nd to be consistent with A WS recommended best practices for security, scalability, a nd resiliency. Which combination of solutions will meet these requirements? (Choose three.)",
      "options": {
        "A": "Create a VPC a cross two A vailability Zones with the a pplication's existing a rchitecture. Host the a pplication with existing a rchitecture on a n A mazon EC2 instance in a private subnet in each A vailability Zone with EC2 A uto Scaling groups. Secure the EC2 instance with security groups a nd network a ccess control lists (network A CLs).",
        "B": "Set up security groups a nd network a ccess control lists (network A CLs) to control a ccess to the database layer. Set up a single A mazon RDS database in a private subnet.",
        "C": "Create a VPC a cross two A vailability Zones. Refactor the a pplication to host the web tier, a pplication tier, a nd database tier. Host each tier on its own private subnet with A uto Scaling groups for the web tier a nd a pplication tier.",
        "D": "Use a single A mazon RDS database. A llow database a ccess only from the a pplication tier security group.",
        "E": "Use Elastic Load Balancers in front of the web tier. Control a ccess by using security groups containing references to each layer's security groups. F. Use a n A mazon RDS database Multi-A Z cluster deployment in private subnets. A llow database a ccess only from a pplication tier security groups."
      },
      "correct_answer": "C",
      "explanation": "This choice a ligns with best practices by using separate subnets for each tier, a llowing for better security a nd scalability. A uto Scaling groups provide elasticity a nd resiliency.\nE. Use Elastic Load Balancers in front of the web tier. Control a ccess by using security groups containing references to each layer's security groups.\nThis option introduces a n Elastic Load Balancer (ELB) for the web tier, which enhances scalability a nd resiliency. Using security groups to control a ccess a dds a n a dditional layer of security.\nF. Use a n A mazon RDS database Multi-A Z cluster deployment in private subnets. A llow database a ccess only from a pplication tier security groups.\nThis option leverages A mazon RDS for the database tier, utilizing Multi-A Z for high a vailability. Placing the RDS database in private subnets a nd restricting a ccess to the a pplication tier security groups enhances security."
    }
  ]
}